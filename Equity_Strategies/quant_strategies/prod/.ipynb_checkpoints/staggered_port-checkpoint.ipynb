{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import sys\n",
    "import re\n",
    "import os.path\n",
    "import yfinance as yf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Ledoit & Wolf constant correlation unequal variance shrinkage estimator.\"\"\"\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def shrinkage(returns: np.array) -> Tuple[np.array, float, float]:\n",
    "    \"\"\"Shrinks sample covariance matrix towards constant correlation unequal variance matrix.\n",
    "    Ledoit & Wolf (\"Honey, I shrunk the sample covariance matrix\", Portfolio Management, 30(2004),\n",
    "    110-119) optimal asymptotic shrinkage between 0 (sample covariance matrix) and 1 (constant\n",
    "    sample average correlation unequal sample variance matrix).\n",
    "    Paper:\n",
    "    http://www.ledoit.net/honey.pdf\n",
    "    Matlab code:\n",
    "    https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-ffff-ffffde5e2d4e/covCor.m.zip\n",
    "    Special thanks to Evgeny Pogrebnyak https://github.com/epogrebnyak\n",
    "    :param returns:\n",
    "        t, n - returns of t observations of n shares.\n",
    "    :return:\n",
    "        Covariance matrix, sample average correlation, shrinkage.\n",
    "    \"\"\"\n",
    "    t, n = returns.shape\n",
    "    mean_returns = np.mean(returns, axis=0, keepdims=True)\n",
    "    returns -= mean_returns\n",
    "    sample_cov = returns.transpose() @ returns / t\n",
    "\n",
    "    # sample average correlation\n",
    "    var = np.diag(sample_cov).reshape(-1, 1)\n",
    "    sqrt_var = var ** 0.5\n",
    "    unit_cor_var = sqrt_var * sqrt_var.transpose()\n",
    "    average_cor = ((sample_cov / unit_cor_var).sum() - n) / n / (n - 1)\n",
    "    prior = average_cor * unit_cor_var\n",
    "    np.fill_diagonal(prior, var)\n",
    "\n",
    "    # pi-hat\n",
    "    y = returns ** 2\n",
    "    phi_mat = (y.transpose() @ y) / t - sample_cov ** 2\n",
    "    phi = phi_mat.sum()\n",
    "\n",
    "    # rho-hat\n",
    "    theta_mat = ((returns ** 3).transpose() @ returns) / t - var * sample_cov\n",
    "    np.fill_diagonal(theta_mat, 0)\n",
    "    rho = (\n",
    "        np.diag(phi_mat).sum()\n",
    "        + average_cor * (1 / sqrt_var @ sqrt_var.transpose() * theta_mat).sum()\n",
    "    )\n",
    "\n",
    "    # gamma-hat\n",
    "    gamma = np.linalg.norm(sample_cov - prior, \"fro\") ** 2\n",
    "\n",
    "    # shrinkage constant\n",
    "    kappa = (phi - rho) / gamma\n",
    "    shrink = max(0, min(1, kappa / t))\n",
    "\n",
    "    # estimator\n",
    "    sigma = shrink * prior + (1 - shrink) * sample_cov\n",
    "\n",
    "    return sigma, average_cor, shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkage_EMW(returns_tmp: np.array, lookback = 252) -> Tuple[np.array, float, float]:\n",
    "    \"\"\"Shrinks sample covariance matrix towards constant correlation unequal variance matrix.\n",
    "    Ledoit & Wolf (\"Honey, I shrunk the sample covariance matrix\", Portfolio Management, 30(2004),\n",
    "    110-119) optimal asymptotic shrinkage between 0 (sample covariance matrix) and 1 (constant\n",
    "    sample average correlation unequal sample variance matrix).\n",
    "    Paper:\n",
    "    http://www.ledoit.net/honey.pdf\n",
    "    Matlab code:\n",
    "    https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-ffff-ffffde5e2d4e/covCor.m.zip\n",
    "    Special thanks to Evgeny Pogrebnyak https://github.com/epogrebnyak\n",
    "    :param returns:\n",
    "        t, n - returns of t observations of n shares.\n",
    "    :return:\n",
    "        Covariance matrix, sample average correlation, shrinkage.\n",
    "    \"\"\"\n",
    "    returns = returns_tmp.tail(lookback).values\n",
    "    t, n = returns.shape\n",
    "    mean_returns = np.mean(returns, axis=0, keepdims=True) # make EWMA\n",
    "    returns -= mean_returns\n",
    "    COV_tmp = returns_tmp.ewm(span = lookback).cov()\n",
    "    idx = returns_tmp.index.get_level_values(0)[-1]\n",
    "    sample_cov = COV_tmp[COV_tmp.index.get_level_values(0) == idx]\n",
    "    sample_cov = sample_cov.values\n",
    "    #sample_cov = returns.transpose() @ returns / t\n",
    "\n",
    "    # sample average correlation\n",
    "    var = np.diag(sample_cov).reshape(-1, 1)\n",
    "    sqrt_var = var ** 0.5\n",
    "    unit_cor_var = sqrt_var * sqrt_var.transpose()\n",
    "    average_cor = ((sample_cov / unit_cor_var).sum() - n) / n / (n - 1)\n",
    "    prior = average_cor * unit_cor_var\n",
    "    np.fill_diagonal(prior, var)\n",
    "\n",
    "    # pi-hat\n",
    "    y = returns ** 2\n",
    "    phi_mat = (y.transpose() @ y) / t - sample_cov ** 2\n",
    "    phi = phi_mat.sum()\n",
    "\n",
    "    # rho-hat\n",
    "    theta_mat = ((returns ** 3).transpose() @ returns) / t - var * sample_cov\n",
    "    np.fill_diagonal(theta_mat, 0)\n",
    "    rho = (\n",
    "        np.diag(phi_mat).sum()\n",
    "        + average_cor * (1 / sqrt_var @ sqrt_var.transpose() * theta_mat).sum()\n",
    "    )\n",
    "\n",
    "    # gamma-hat\n",
    "    gamma = np.linalg.norm(sample_cov - prior, \"fro\") ** 2\n",
    "\n",
    "    # shrinkage constant\n",
    "    kappa = (phi - rho) / gamma\n",
    "    shrink = max(0, min(1, kappa / t))\n",
    "\n",
    "    # estimator\n",
    "    sigma = shrink * prior + (1 - shrink) * sample_cov\n",
    "\n",
    "    return sigma, average_cor, shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import ezodf\n",
    "import scipy.optimize as sco\n",
    "import scipy\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "def Optimize_Portfolio(data ,lookback = 252, risk_free = 0, objective = 'Kelly'):\n",
    "\n",
    "    ret = (data-1).mean()\n",
    "    #cov_fit = LedoitWolf().fit(data)\n",
    "    #cov = cov_fit.covariance_\n",
    "    cov, average_cor, shrink = shrinkage_EMW(data, lookback = lookback)\n",
    "    #cov = PCA_cov(data, N=5)\n",
    "   \n",
    "  \n",
    "    if objective == 'Max Div':\n",
    "        num_assets = len(data.columns)\n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(calc_diversification_ratio, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "    elif objective == \"min var\":\n",
    "        num_assets = len(data.columns)\n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(port_var, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "    elif objective == \"erc\":\n",
    "        num_assets = len(data.columns) \n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
    "                      {'type':'ineq', 'fun': lambda x: x-(1/num_assets)*0.7}, # min position\n",
    "                      {'type':'ineq', 'fun': lambda x: (1/num_assets)*1.3-x}) # max position\n",
    "        \n",
    "        result = sco.minimize(erc, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "\n",
    "    return (result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def port_var(weights, cov):\n",
    "    var = weights.dot(cov).dot(weights)\n",
    "    return(var)\n",
    "\n",
    "def port_ret(weights, ret, risk_free = 0):\n",
    "    #needs to be array\n",
    "    ret = ret - risk_free\n",
    "    port_ret = weights.dot(ret)\n",
    "    return(port_ret)\n",
    "\n",
    "def risk_parity(data):\n",
    "    vol = np.log((data)).std()\n",
    "\n",
    "    sum_vol = 0\n",
    "    for i in range(len(vol)):\n",
    "        sum_vol =sum_vol + (1/vol[i])\n",
    "    \n",
    "    weight = []\n",
    "    for i in range(len(vol)):\n",
    "        w = (1/vol[i])/(sum_vol)\n",
    "        weight.append(w)\n",
    "   \n",
    "    weight = [round(num, 2) for num in weight]\n",
    "    return(weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_diversification_ratio(weights, cov):\n",
    "    # average weighted vol\n",
    "    w_vol = np.dot(np.sqrt(np.diag(cov)), weights.T)\n",
    "    # portfolio vol\n",
    "    port_vol = np.sqrt(port_var(weights, cov))\n",
    "    \n",
    "    diversification_ratio = w_vol/port_vol\n",
    "    # return negative for minimization problem (maximize = minimize -)\n",
    "    return -diversification_ratio\n",
    "\n",
    "def erc(weights, cov):\n",
    "        # these are non normalized risk contributions, i.e. not regularized\n",
    "        # by total risk, seems to help numerically\n",
    "        risk_contributions = np.dot(weights, cov) * weights\n",
    "        a = np.reshape(risk_contributions, (len(risk_contributions), 1))\n",
    "        # broadcasts so you get pairwise differences in risk contributions\n",
    "        risk_diffs = a - a.transpose()\n",
    "        sum_risk_diffs_squared = np.sum(np.square(np.ravel(risk_diffs)))\n",
    "        # https://stackoverflow.com/a/36685019/1451311\n",
    "        return sum_risk_diffs_squared #/ scale_factorcov\n",
    "    \n",
    "\n",
    "\n",
    "import sklearn.datasets, sklearn.decomposition\n",
    "\n",
    "def PCA_cov(data, N = 5):\n",
    "    \n",
    "    X = data.ewm(span = 252).cov()\n",
    "    DATE_IDX = X.index.get_level_values(level=0)[-1]\n",
    "    X = X[X.index.get_level_values(0)==DATE_IDX].droplevel(0)\n",
    "    mu = np.mean(X, axis=0)\n",
    "\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca.fit(X)\n",
    "\n",
    "    nComp = N\n",
    "    Xhat = np.dot(pca.transform(X)[:,:nComp], pca.components_[:nComp,:])\n",
    "    Xhat += mu\n",
    "    clean_cov = pd.DataFrame(Xhat)\n",
    "    clean_cov.index = X.index\n",
    "    clean_cov.columns = X.index\n",
    "    return(clean_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERC_gestalt(data, lookback = 252):\n",
    "    \n",
    "    prices_df = pd.DataFrame()\n",
    "    for tick in data['Yahoo']:\n",
    "    \n",
    "        price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "        price = price['Adj Close']\n",
    "        prices_df[tick] = price\n",
    "    \n",
    "    log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "    log_ret = log_ret.dropna()\n",
    "    weight = Optimize_Portfolio(log_ret, lookback = lookback, objective='erc')['x'].round(3)\n",
    "\n",
    "    return(weight)\n",
    "\n",
    "def round_to_multiple(number, multiple):\n",
    "    return multiple * round(number / multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import old portfolios to construct staggerd portfolio\n",
    "\n",
    "- Q: How to handel \"hold\" positions?\n",
    "- \"Hold\" companies shold have \"Min Position\" == ACTION/3 rest is weighted from this? and MAX = Average posiotn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eriks_port = ['B3 Consulting',\n",
    "'Nilörngruppen','Kabe','Björn Borg','BE Group','Poolia','New Wave',\n",
    "'Softronic','SSAB B', 'Dedicare','Africa Oil','TietoEVRY',\n",
    "'Prevas','Byggpartner','Clas Ohlson', 'Transtema','Ericsson B']\n",
    "\n",
    "jonas_port = ['B3 Consulting',\n",
    "'Nilörngruppen','Kabe','Björn Borg','BE Group','Poolia','New Wave',\n",
    "'Softronic','SSAB B', 'Dedicare','Africa Oil','TietoEVRY',\n",
    "'Prevas','Byggpartner','Clas Ohlson', 'Transtema',\"Ogunsen\" , \"ProfilGruppen\", \"Rottneros\"]\n",
    "\n",
    "lindas_port = ['Björn Borg','BE Group','Clas Ohlson','Nilörngruppen','B3 Consulting','Poolia','Kabe',\n",
    " 'New Wave', 'Softronic', 'SSAB B', 'Africa Oil', 'Transtema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../clean_equity_data/\"\n",
    "#file_list = [\"GESTALT_2022-02-26.csv\",\"GESTALT_2022-03-30.csv\",\"GESTALT_2022-04-28.csv\" ]\n",
    "#N_stocks = [15,15,20]\n",
    "#STAGGS = 3\n",
    "\n",
    "file_list = ['GESTALT_2022-05-24.csv']\n",
    "N_stocks = [15]\n",
    "STAGGS = 1\n",
    "current_port = eriks_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_tmp = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    N = N_stocks[file_list.index(file)]\n",
    "    data_tmp = pd.read_csv(folder + file)\n",
    "    buy = data_tmp[0:N][['Company','Yahoo' ,'Gestalt Rank']]\n",
    "    \n",
    "    #ONLY KEEP THE HOLD SPREAD FOR THE LAST MONTH? \n",
    "    hold = data_tmp[N: 2*N][['Company','Yahoo', 'Gestalt Rank']] # update to latest month spread??\n",
    "    keep = hold[hold['Company'].isin(current_port)]\n",
    "    \n",
    "    opt_port = pd.concat([buy,keep])\n",
    "    opt_port.loc[: ,'WEIGHT'] = ERC_gestalt(opt_port)\n",
    "    port_tmp = pd.concat([port_tmp,opt_port])\n",
    "    \n",
    "    \n",
    "port_tmp = port_tmp.groupby(['Company']).sum()[['WEIGHT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SELL THESE HOLDINGS\n",
    "SELL_LIST =pd.DataFrame(list(set(current_port) - set(port_tmp.index)),columns = ['Company'] )\n",
    "SELL_LIST = SELL_LIST.groupby(['Company']).sum()\n",
    "#Buy these holding\n",
    "BUY_LIST = pd.DataFrame(list(set(port_tmp.index) - set(current_port)),columns = ['Company'])\n",
    "BUY_LIST = BUY_LIST.groupby(['Company']).sum()\n",
    "\n",
    "\n",
    "port_tmp.loc[: ,'WEIGHT'] = (port_tmp['WEIGHT']*100).round(decimals=1)\n",
    "FINAL_PORT = pd.DataFrame(port_tmp['WEIGHT'])\n",
    "FINAL_PORT = FINAL_PORT.sort_values(by = 'WEIGHT', ascending=False)\n",
    "FINAL_PORT['WEIGHT'] = (FINAL_PORT['WEIGHT']/FINAL_PORT['WEIGHT'].sum()).apply(lambda x: round_to_multiple(x, 0.005))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEIGHT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TietoEVRY</th>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betsson</th>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clas Ohlson</th>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Softronic</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilia</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rottneros</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Björn Borg</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arctic Paper</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSAB B</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Africa Oil</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnQuest</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dedicare</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poolia</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kabe</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nilörngruppen</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3 Consulting</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novotek</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevas</th>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Wave</th>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BE Group</th>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               WEIGHT\n",
       "Company              \n",
       "TietoEVRY       0.065\n",
       "Betsson         0.060\n",
       "Clas Ohlson     0.060\n",
       "Softronic       0.055\n",
       "Bilia           0.055\n",
       "Rottneros       0.055\n",
       "Björn Borg      0.055\n",
       "Arctic Paper    0.050\n",
       "SSAB B          0.050\n",
       "Africa Oil      0.050\n",
       "EnQuest         0.050\n",
       "Dedicare        0.050\n",
       "Poolia          0.050\n",
       "Kabe            0.045\n",
       "Nilörngruppen   0.045\n",
       "B3 Consulting   0.045\n",
       "Novotek         0.045\n",
       "Prevas          0.040\n",
       "New Wave        0.035\n",
       "BE Group        0.035"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Byggpartner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ericsson B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transtema</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Byggpartner, Ericsson B, Transtema]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELL_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arctic Paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betsson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnQuest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novotek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rottneros</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Arctic Paper, Betsson, Bilia, EnQuest, Novotek, Rottneros]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUY_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_PORT.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = opt_port\n",
    "lookbacks = [126,252, 504]\n",
    "prices_df = pd.DataFrame()\n",
    "weights_df =  pd.DataFrame()\n",
    "for tick in data['Yahoo']:\n",
    "    \n",
    "    price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "    price = price['Adj Close']\n",
    "    prices_df[tick] = price\n",
    "    \n",
    "for look in lookbacks:\n",
    "    log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "    log_ret = log_ret.dropna()\n",
    "    weight_tmp = Optimize_Portfolio(log_ret, lookback = look, objective='erc')['x'].round(3)\n",
    "    weights_df[look] = weight_tmp\n",
    "\n",
    "weight = weights_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
