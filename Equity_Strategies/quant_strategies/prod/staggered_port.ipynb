{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import sys\n",
    "import re\n",
    "import os.path\n",
    "import yfinance as yf \n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats.mstats import winsorize\n",
    "import os\n",
    "import glob\n",
    "import dateutil.parser as dparser\n",
    "\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Ledoit & Wolf constant correlation unequal variance shrinkage estimator.\"\"\"\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "def shrinkage(returns: np.array) -> Tuple[np.array, float, float]:\n",
    "    \"\"\"Shrinks sample covariance matrix towards constant correlation unequal variance matrix.\n",
    "    Ledoit & Wolf (\"Honey, I shrunk the sample covariance matrix\", Portfolio Management, 30(2004),\n",
    "    110-119) optimal asymptotic shrinkage between 0 (sample covariance matrix) and 1 (constant\n",
    "    sample average correlation unequal sample variance matrix).\n",
    "    Paper:\n",
    "    http://www.ledoit.net/honey.pdf\n",
    "    Matlab code:\n",
    "    https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-ffff-ffffde5e2d4e/covCor.m.zip\n",
    "    Special thanks to Evgeny Pogrebnyak https://github.com/epogrebnyak\n",
    "    :param returns:\n",
    "        t, n - returns of t observations of n shares.\n",
    "    :return:\n",
    "        Covariance matrix, sample average correlation, shrinkage.\n",
    "    \"\"\"\n",
    "    t, n = returns.shape\n",
    "    mean_returns = np.mean(returns, axis=0, keepdims=True)\n",
    "    returns -= mean_returns\n",
    "    sample_cov = returns.transpose() @ returns / t\n",
    "\n",
    "    # sample average correlation\n",
    "    var = np.diag(sample_cov).reshape(-1, 1)\n",
    "    sqrt_var = var ** 0.5\n",
    "    unit_cor_var = sqrt_var * sqrt_var.transpose()\n",
    "    average_cor = ((sample_cov / unit_cor_var).sum() - n) / n / (n - 1)\n",
    "    prior = average_cor * unit_cor_var\n",
    "    np.fill_diagonal(prior, var)\n",
    "\n",
    "    # pi-hat\n",
    "    y = returns ** 2\n",
    "    phi_mat = (y.transpose() @ y) / t - sample_cov ** 2\n",
    "    phi = phi_mat.sum()\n",
    "\n",
    "    # rho-hat\n",
    "    theta_mat = ((returns ** 3).transpose() @ returns) / t - var * sample_cov\n",
    "    np.fill_diagonal(theta_mat, 0)\n",
    "    rho = (\n",
    "        np.diag(phi_mat).sum()\n",
    "        + average_cor * (1 / sqrt_var @ sqrt_var.transpose() * theta_mat).sum()\n",
    "    )\n",
    "\n",
    "    # gamma-hat\n",
    "    gamma = np.linalg.norm(sample_cov - prior, \"fro\") ** 2\n",
    "\n",
    "    # shrinkage constant\n",
    "    kappa = (phi - rho) / gamma\n",
    "    shrink = max(0, min(1, kappa / t))\n",
    "\n",
    "    # estimator\n",
    "    sigma = shrink * prior + (1 - shrink) * sample_cov\n",
    "\n",
    "    return sigma, average_cor, shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkage_EMW(returns_tmp: np.array, lookback = 126) -> Tuple[np.array, float, float]:\n",
    "    \"\"\"Shrinks sample covariance matrix towards constant correlation unequal variance matrix.\n",
    "    Ledoit & Wolf (\"Honey, I shrunk the sample covariance matrix\", Portfolio Management, 30(2004),\n",
    "    110-119) optimal asymptotic shrinkage between 0 (sample covariance matrix) and 1 (constant\n",
    "    sample average correlation unequal sample variance matrix).\n",
    "    Paper:\n",
    "    http://www.ledoit.net/honey.pdf\n",
    "    Matlab code:\n",
    "    https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-ffff-ffffde5e2d4e/covCor.m.zip\n",
    "    Special thanks to Evgeny Pogrebnyak https://github.com/epogrebnyak\n",
    "    :param returns:\n",
    "        t, n - returns of t observations of n shares.\n",
    "    :return:\n",
    "        Covariance matrix, sample average correlation, shrinkage.\n",
    "    \"\"\"\n",
    "    returns = returns_tmp.tail(lookback).values\n",
    "    t, n = returns.shape\n",
    "    mean_returns = np.mean(returns, axis=0, keepdims=True) # make EWMA\n",
    "    returns -= mean_returns\n",
    "    COV_tmp = returns_tmp.ewm(span = lookback).cov()\n",
    "    idx = returns_tmp.index.get_level_values(0)[-1]\n",
    "    sample_cov = COV_tmp[COV_tmp.index.get_level_values(0) == idx]\n",
    "    sample_cov = sample_cov.values\n",
    "    #sample_cov = returns.transpose() @ returns / t\n",
    "\n",
    "    # sample average correlation\n",
    "    var = np.diag(sample_cov).reshape(-1, 1)\n",
    "    sqrt_var = var ** 0.5\n",
    "    unit_cor_var = sqrt_var * sqrt_var.transpose()\n",
    "    average_cor = ((sample_cov / unit_cor_var).sum() - n) / n / (n - 1)\n",
    "    prior = average_cor * unit_cor_var\n",
    "    np.fill_diagonal(prior, var)\n",
    "\n",
    "    # pi-hat\n",
    "    y = returns ** 2\n",
    "    phi_mat = (y.transpose() @ y) / t - sample_cov ** 2\n",
    "    phi = phi_mat.sum()\n",
    "\n",
    "    # rho-hat\n",
    "    theta_mat = ((returns ** 3).transpose() @ returns) / t - var * sample_cov\n",
    "    np.fill_diagonal(theta_mat, 0)\n",
    "    rho = (\n",
    "        np.diag(phi_mat).sum()\n",
    "        + average_cor * (1 / sqrt_var @ sqrt_var.transpose() * theta_mat).sum()\n",
    "    )\n",
    "\n",
    "    # gamma-hat\n",
    "    gamma = np.linalg.norm(sample_cov - prior, \"fro\") ** 2\n",
    "\n",
    "    # shrinkage constant\n",
    "    kappa = (phi - rho) / gamma\n",
    "    shrink = max(0, min(1, kappa / t))\n",
    "\n",
    "    # estimator\n",
    "    sigma = shrink * prior + (1 - shrink) * sample_cov\n",
    "\n",
    "    return sigma, average_cor, shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import ezodf\n",
    "import scipy.optimize as sco\n",
    "import scipy\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "def Optimize_Portfolio(data ,lookback = 126, risk_free = 0, objective = 'Kelly'):\n",
    "\n",
    "    ret = (data-1).mean()\n",
    "    #cov_fit = LedoitWolf().fit(data)\n",
    "    #cov = cov_fit.covariance_\n",
    "    cov, average_cor, shrink = shrinkage_EMW(data, lookback = lookback)\n",
    "    #cov = PCA_cov(data, N=5)\n",
    "   \n",
    "  \n",
    "    if objective == 'Max Div':\n",
    "        num_assets = len(data.columns)\n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(calc_diversification_ratio, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "    elif objective == \"min var\":\n",
    "        num_assets = len(data.columns)\n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(port_var, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "    elif objective == \"erc\":\n",
    "        num_assets = len(data.columns) \n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
    "                      {'type':'ineq', 'fun': lambda x: x-(1/num_assets)*0.7}, # min position\n",
    "                      {'type':'ineq', 'fun': lambda x: (1/num_assets)*1.3-x}) # max position\n",
    "        \n",
    "        result = sco.minimize(erc, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints,\n",
    "                                   options={'disp': True, 'maxiter': 100000, 'ftol' : 1e-100000,\n",
    "                      'eps':1e-6}, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "\n",
    "    return (result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def port_var(weights, cov):\n",
    "    var = weights.dot(cov).dot(weights)\n",
    "    return(var)\n",
    "\n",
    "def port_ret(weights, ret, risk_free = 0):\n",
    "    #needs to be array\n",
    "    ret = ret - risk_free\n",
    "    port_ret = weights.dot(ret)\n",
    "    return(port_ret)\n",
    "\n",
    "def risk_parity(data):\n",
    "    vol = np.log((data)).std()\n",
    "\n",
    "    sum_vol = 0\n",
    "    for i in range(len(vol)):\n",
    "        sum_vol =sum_vol + (1/vol[i])\n",
    "    \n",
    "    weight = []\n",
    "    for i in range(len(vol)):\n",
    "        w = (1/vol[i])/(sum_vol)\n",
    "        weight.append(w)\n",
    "   \n",
    "    weight = [round(num, 2) for num in weight]\n",
    "    return(weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_diversification_ratio(weights, cov):\n",
    "    # average weighted vol\n",
    "    w_vol = np.dot(np.sqrt(np.diag(cov)), weights.T)\n",
    "    # portfolio vol\n",
    "    port_vol = np.sqrt(port_var(weights, cov))\n",
    "    \n",
    "    diversification_ratio = w_vol/port_vol\n",
    "    # return negative for minimization problem (maximize = minimize -)\n",
    "    return -diversification_ratio\n",
    "\n",
    "def erc(weights, cov):\n",
    "        # these are non normalized risk contributions, i.e. not regularized\n",
    "        # by total risk, seems to help numerically\n",
    "        risk_contributions = np.dot(weights, cov) * weights\n",
    "        a = np.reshape(risk_contributions, (len(risk_contributions), 1))\n",
    "        # broadcasts so you get pairwise differences in risk contributions\n",
    "        risk_diffs = a - a.transpose()\n",
    "        sum_risk_diffs_squared = np.sum(np.square(np.ravel(risk_diffs)))\n",
    "        # https://stackoverflow.com/a/36685019/1451311\n",
    "        return sum_risk_diffs_squared #/ scale_factorcov\n",
    "    \n",
    "\n",
    "\n",
    "import sklearn.datasets, sklearn.decomposition\n",
    "\n",
    "def PCA_cov(data, N = 5):\n",
    "    \n",
    "    X = data.ewm(span = 252).cov()\n",
    "    DATE_IDX = X.index.get_level_values(level=0)[-1]\n",
    "    X = X[X.index.get_level_values(0)==DATE_IDX].droplevel(0)\n",
    "    mu = np.mean(X, axis=0)\n",
    "\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca.fit(X)\n",
    "\n",
    "    nComp = N\n",
    "    Xhat = np.dot(pca.transform(X)[:,:nComp], pca.components_[:nComp,:])\n",
    "    Xhat += mu\n",
    "    clean_cov = pd.DataFrame(Xhat)\n",
    "    clean_cov.index = X.index\n",
    "    clean_cov.columns = X.index\n",
    "    return(clean_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERC_gestalt(data, lookback = 126):\n",
    "    \n",
    "    prices_df = pd.DataFrame()\n",
    "    for tick in data['Yahoo']:\n",
    "    \n",
    "        price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "        price = price['Adj Close']\n",
    "        prices_df[tick] = price\n",
    "    \n",
    "    log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "    log_ret = log_ret.dropna()\n",
    "    \n",
    "    weight = Optimize_Portfolio(log_ret, lookback = lookback, objective='erc')['x'].round(3)\n",
    "\n",
    "    return(weight)\n",
    "\n",
    "def round_to_multiple(number, multiple):\n",
    "    return multiple * round(number / multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import old portfolios to construct staggerd portfolio\n",
    "\n",
    "- Q: How to handel \"hold\" positions?\n",
    "- \"Hold\" companies shold have \"Min Position\" == ACTION/3 rest is weighted from this? and MAX = Average posiotn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 332/482 [01:56<00:42,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- SDIP.ST: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [02:50<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "### Settings\n",
    "START_DATE = '2016-01-01'\n",
    "error_count = 0\n",
    "error_list = []\n",
    "\n",
    "\n",
    "latest_file= max(glob.glob(\"../equity_data/*.*\"), key=os.path.getmtime)\n",
    "\n",
    "signal_df = pd.read_excel(latest_file, sheet_name=\"Export\")\n",
    "signal_df = signal_df.rename({'Performance - Perform. 3m' : 'Return 3m','Performance - Perform. 6m' : 'Return 6m',\n",
    "                            'Total Return - Return 1y' : 'Return 1y',\n",
    "                            'Div. Yield - Current': 'Yield',\n",
    "                            'Total Equity  - Millions':'Total Equity', 'FCF - Millions': 'FCF','ROE - Current':'ROE',\n",
    "                            'Volatility - St.Dev. 100d':'Volatility','Market Cap - Current': 'Market Cap', \n",
    "                            'ROC - Current':'ROC', 'Tot. Assets - Millions':'Tot. Assets', \n",
    "                            'Gross profit - Millions':'Gross profit', 'Assets Turn - Current': 'Assets Turn',\n",
    "                            'P/FCF - Current':'P/FCF', 'P/E - Current':'P/E', 'P/S - Current':'P/S',\n",
    "                            'P/B - Current':'P/B','EV/EBIT - Current':'EV/EBIT',\n",
    "                            'Info - Country' : 'Country','F-Score - Point':'F-Score',\n",
    "                            'Info - List' : 'List', 'Info - Sector' : 'Sector', 'Info - Industry' : 'Industry',\n",
    "                            'Info - Ticker' : 'Ticker', 'Info - Yahoo':'Yahoo', 'Info - Last Report': 'Last Report',\n",
    "                           'Volume - Average 50d Mill' : 'Volume', 'Tot. Assets - Growth 1y' : 'Asset Growth'}, axis=1)\n",
    "\n",
    "\n",
    "signal_df = signal_df.loc[ (signal_df['List'] != 'Spotlight') \n",
    "                        & (signal_df['List'] != 'NGM') & (signal_df['Country'] == \"Sweden\") &\n",
    "                         (signal_df['Market Cap'] > 200)]\n",
    "\n",
    "signal_df = signal_df.loc[(signal_df['Sector'] != 'Financials')]\n",
    "\n",
    "# Set to dattime\n",
    "signal_df['Last Report'] = pd.to_datetime(signal_df['Last Report'])\n",
    "#set new index\n",
    "signal_df.index = range(len(signal_df.index))\n",
    "\n",
    "\n",
    "signal_df['Res_Mom_1M'] = np.nan\n",
    "signal_df['Res_Mom_1M_alt'] = np.nan\n",
    "\n",
    "signal_df['Tot_Mom_1M'] = np.nan\n",
    "signal_df['Sea_month_5yr'] = np.nan\n",
    "signal_df['idio_vol_20day'] = np.nan\n",
    "signal_df['maxret_5days'] = np.nan\n",
    "signal_df[\"EAR_std\"]= np.nan\n",
    "signal_df[\"5yr_vol\"]= np.nan\n",
    "signal_df[\"liq_shock\"]= np.nan\n",
    "\n",
    "index = yf.download('^OMXSPI',start=START_DATE, threads = False, progress = False)\n",
    "index = index['Adj Close']\n",
    "for i in tqdm(range(len(signal_df))):\n",
    "\n",
    "    try:\n",
    "        stock_tmp = yf.download(signal_df.iloc[i]['Yahoo'],start=START_DATE, progress = False, threads = False)\n",
    "\n",
    "        \n",
    "        stock = stock_tmp['Adj Close']\n",
    "        import_data = pd.concat([stock, index], axis = 1)\n",
    "        import_data.columns = ['stock', 'index']\n",
    "        import_data = import_data.dropna()\n",
    "        \n",
    "        long_df = import_data.copy()\n",
    "        ret_df = np.log(import_data/import_data.shift()).dropna()\n",
    "        ### SEASONALITY\n",
    "        \n",
    "        monthly_df = import_data.resample('M').last()\n",
    "        monthly_ret_df = np.log(monthly_df/monthly_df.shift()).dropna()\n",
    "         \n",
    "        ### 1 Month Momentum\n",
    "        signal_df.loc[i,\"Tot_Mom_1M\"] = ret_df['stock'].tail(21).sum()\n",
    "        \n",
    "        \n",
    "        ##EAR\n",
    "        idx = ret_df.index.get_loc(signal_df.iloc[i]['Last Report'], method='nearest')\n",
    "        \n",
    "        EA_data = import_data.iloc[idx - 2 : idx +2 ]\n",
    "        \n",
    "        EA_ret = (EA_data.pct_change().dropna()+1).cumprod().tail(1)\n",
    "        pead_ret = float(EA_ret['stock'] - EA_ret['index']) #Should use np.log()\n",
    "        pead_vol = np.log(stock.iloc[:idx]/stock.iloc[:idx].shift()).tail(60).std()*252**.5\n",
    "        signal_df.loc[i, 'EAR_std'] = pead_ret/pead_vol\n",
    "        \n",
    "        ## liquidity shock\n",
    "        \n",
    "        stock_volume = stock_tmp.copy()\n",
    "        stock_volume['volume_sek'] = stock_volume['Close'] *stock_volume['Volume']\n",
    "        \n",
    "        # Resample to monthly for sobustness???\n",
    "        stock_volume = stock_volume.rolling(21).sum().resample('30D').last()\n",
    "        \n",
    "\n",
    "        liq_shock = (stock_volume['volume_sek'].tail(1) - stock_volume['volume_sek'].tail(12).mean())/stock_volume['volume_sek'].tail(12).std()\n",
    "        signal_df.loc[i,\"liq_shock\"] = float(liq_shock)\n",
    "        \n",
    "        ### RESIDUAL MOMENTUM\n",
    "        ret_trim_df = ret_df.drop(ret_df.iloc[[idx - 1, idx, idx +1, idx +2 ]].index)\n",
    "        \n",
    "        \n",
    "        signal_df.loc[i,\"maxret_5days\"] = np.mean(sorted(ret_trim_df['stock'].tail(21))[-5:])\n",
    "        y_res = ret_trim_df.tail(21)['stock']\n",
    "        X_res = np.array(ret_trim_df.tail(21)['index']).reshape(-1, 1)\n",
    "        reg_res = LinearRegression().fit(X_res, y_res)\n",
    "        residuals_res = y_res - reg_res.predict(X_res)\n",
    "        signal_df.loc[i,\"idio_vol_20day\"] = residuals_res.std()\n",
    "        \n",
    "        #volume weight for short term rev\n",
    "        vol_weight_tmp = stock_tmp.copy()\n",
    "        vol_weight_tmp['volume_sek'] = vol_weight_tmp['Close'] *vol_weight_tmp['Volume']\n",
    "        #weight by 60 day MA\n",
    "        vol_weight = vol_weight_tmp['volume_sek'].rolling(252).mean() / vol_weight_tmp['volume_sek']\n",
    "        \n",
    "        reg_df = ret_trim_df.tail(3*252)\n",
    "        ## Identify Report \n",
    "        if len(reg_df)>(2*252):\n",
    "            y = reg_df['stock']\n",
    "            X = np.array(reg_df['index']).reshape(-1, 1)\n",
    "            reg = LinearRegression().fit(X, y)\n",
    "            beta = reg.coef_[0]\n",
    "            residuals = y - reg.predict(X)\n",
    "            std_residuals = residuals/residuals.std()\n",
    "            \n",
    "            signal_df.loc[i,\"Res_Mom_1M\"] = std_residuals.tail(21).sum()# + np.log(vol_weight.tail(21)).sum()\n",
    "           \n",
    "        \n",
    "        if len(monthly_ret_df)>=36:\n",
    "            seas_list = []\n",
    "            monthly_vol = 0\n",
    "            for look in [12,24,36,48,60]:\n",
    "                try:\n",
    "                    seas_list.append(monthly_ret_df['stock'].iloc[-look])\n",
    "                    monthly_vol = (monthly_ret_df['stock'].tail(60)+1).std() * np.sqrt(12)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "            signal_df.loc[i,\"Sea_month_5yr\"] = np.mean(seas_list) *12\n",
    "            signal_df.loc[i,\"5yr_vol\"] = monthly_vol\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        error_count = error_count + 1\n",
    "        error_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../equity_data/Borsdata_2022-08-27.xlsx'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### CREATE NEW SECTORS!\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Leisure', 'Gambling & Casinos','Airlines','Hotels']),'Sector'] = 'Travel & Leisure'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Pharmaceuticals']),'Sector'] = 'Pharmaceuticals'\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Medical Equipment']),'Sector'] = 'Medical Equipment'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Retailers','Auto & Equipment','Industrial Components', 'Clothing & Footwear',\n",
    "    'Consumer Electronics', 'Accessories' ]),'Sector'] = 'Retail'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['IT Consulting', 'IT Services', 'Communications',]),'Sector'] = 'Software'\n",
    "\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Industrial Components',\n",
    "    'Energy & Recycling' ]),'Sector'] = 'General Industrials'\n",
    "\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Construction Supplies','Construction & Infrastructure',\n",
    "     'Installation']),'Sector'] = 'Construction & Materials' \n",
    "\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Industrial Machinery', 'Electrical Components']),'Sector'] = 'Electronic & Electrical Equipment'\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Holding Companies']),'Sector'] = 'Holding Companies'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Real Estate']),'Sector'] = 'Real Estate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_df['Industry'].unique()\n",
    "\n",
    "#signal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CUTOFF = 0.33 #0.25 # which cut off??\n",
    "\n",
    "method = 'median'\n",
    "\n",
    "### SHORT TERM REVERSAL - adjust for industry ###\n",
    "signal_df['Res_Mom_1M_adj'] = signal_df[\"Res_Mom_1M\"] - signal_df.groupby(\"Sector\")[\"Res_Mom_1M\"].transform(method)\n",
    "\n",
    "\n",
    "#Vol adjsuted Seasonality\n",
    "signal_df['Sea_month_5yr_std'] = signal_df['Sea_month_5yr']/signal_df['5yr_vol']\n",
    "\n",
    "### IVOL - adjust for industry\n",
    "\n",
    "signal_df['idio_vol_20day_adj'] = signal_df[\"idio_vol_20day\"] - signal_df.groupby(\"Sector\")[\"idio_vol_20day\"].transform(method)\n",
    "\n",
    "\n",
    "## MAX RET - adjust for industry\n",
    "signal_df['maxret_5days_adj'] = signal_df[\"maxret_5days\"] - signal_df.groupby(\"Sector\")[\"maxret_5days\"].transform(method)\n",
    "\n",
    "\n",
    "\n",
    "########## INDUSTRY MOMENTUM ASSNESS SHOWS THAT EQUAL WEIGHT WORKS\n",
    "signal_df['Sector Weighted Mom'] = signal_df.groupby(\"Sector\")[\"Tot_Mom_1M\"].transform(method)\n",
    "\n",
    "# IMPUTE MEDIAN VALUE FOR NANS\n",
    "signal_df['Res_Mom_1M_adj'] = signal_df['Res_Mom_1M_adj'].fillna(signal_df['Res_Mom_1M'].median())\n",
    "\n",
    "### SEASONALITY\n",
    "signal_df['Sea_month_5yr_std'] = signal_df['Sea_month_5yr_std'].fillna(signal_df['Sea_month_5yr_std'].median())\n",
    "### SHORT TERM IVOL\n",
    "signal_df['idio_vol_20day_adj'] = signal_df['idio_vol_20day_adj'].fillna(signal_df['idio_vol_20day'].median())\n",
    "### MAX RET\n",
    "signal_df['maxret_5days_adj'] = signal_df['maxret_5days_adj'].fillna(signal_df['maxret_5days_adj'].median())\n",
    "# Ear \n",
    "signal_df['EAR_std'] = signal_df['EAR_std'].fillna(signal_df['EAR_std'].median())\n",
    "# Liquidity Shock\n",
    "signal_df['liq_shock'] = signal_df['liq_shock'].fillna(signal_df['liq_shock'].median())\n",
    "\n",
    "\n",
    "\n",
    "######### RANK ON INDIVIDUAL PREDICTORS\n",
    "signal_df['Res_Mom_1M_adj_rank'] = signal_df['Res_Mom_1M_adj'].rank(ascending=True, pct = True)\n",
    "#high is good\n",
    "signal_df['Sector Momentum Rank'] =  signal_df['Sector Weighted Mom'].rank(ascending=False, pct = True)\n",
    "#high is good\n",
    "signal_df['Seasonality Rank'] =  signal_df['Sea_month_5yr'].rank(ascending=False, pct = True)\n",
    "#high is good\n",
    "signal_df['Seasonality Rank Std'] =  signal_df['Sea_month_5yr_std'].rank(ascending=False, pct = True)\n",
    "#low is good\n",
    "signal_df['IVOL_adj Rank'] =  signal_df['idio_vol_20day_adj'].rank(ascending=True, pct = True)\n",
    "#low is good\n",
    "signal_df['MAXRET_adj Rank'] =  signal_df['maxret_5days_adj'].rank(ascending=True, pct = True)\n",
    "#high is good\n",
    "signal_df['EAR_std Rank'] =  signal_df['EAR_std'].rank(ascending=False, pct = True)\n",
    "#high is good\n",
    "signal_df['liq_shock Rank'] =  signal_df['liq_shock'].rank(ascending=False, pct = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################# YOU WANT THE LOWEST SCORE POSSIBLE\n",
    "## USE PCT. \n",
    "## Implement an interaction score for liquidity and SREV \n",
    "\n",
    "signal_df['High_Freq_Combo'] = ( signal_df['Sector Momentum Rank'] +\n",
    "                               signal_df['Res_Mom_1M_adj_rank'] +\n",
    "                               signal_df['Seasonality Rank Std'] +  signal_df['EAR_std Rank'] +\n",
    "                                signal_df['liq_shock Rank']+\n",
    "                                0.5*signal_df['IVOL_adj Rank'] + 0.5*signal_df['MAXRET_adj Rank']\n",
    "                                ).rank(ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "signal_df['Signal'] = \"Neutral\"\n",
    "idx_BUY = signal_df['High_Freq_Combo']<=signal_df['High_Freq_Combo'].quantile(CUTOFF)\n",
    "signal_df.loc[idx_BUY,'Signal']= 'Buy'\n",
    "\n",
    "\n",
    "idx_SELL = signal_df['High_Freq_Combo']>=signal_df['High_Freq_Combo'].quantile(1-CUTOFF)\n",
    "signal_df.loc[idx_SELL,'Signal'] = 'Sell'\n",
    "rank_data = signal_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../clean_equity_data/\"\n",
    "\n",
    "port_file = (\"../portfolios/eriks_port.xlsx\")\n",
    "SPREAD = 3\n",
    "\n",
    "current_port_tmp = pd.read_excel(port_file)\n",
    "current_port_tmp = current_port_tmp.loc[current_port_tmp['Current %']>0,]\n",
    "current_port_tmp = current_port_tmp.loc[~current_port_tmp['Company'].isin([\"Cash\", \"Total\"])]\n",
    "current_port = current_port_tmp['Company']\n",
    "\n",
    "\n",
    "\n",
    "# file_list = [\"GESTALT_2022-06-29.csv\",\"GESTALT_2022-07-28.csv\", \"GESTALT_2022-08-27.csv\" ]\n",
    "# N_stocks = [20,20,15]\n",
    "\n",
    "\n",
    "file_list =['GESTALT_2022-08-27.csv', 'GESTALT_2022-08-27.csv', 'GESTALT_2022-08-27.csv']\n",
    "N_stocks = [10, 10, 10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Arctic Paper\n",
       "1                    Dedicare\n",
       "2                   Rottneros\n",
       "3     International Petroleum\n",
       "4                      SSAB B\n",
       "5                     EnQuest\n",
       "6               B3 Consulting\n",
       "7                    New Wave\n",
       "8                     Betsson\n",
       "9                      Prevas\n",
       "11              Nilörngruppen\n",
       "13                   BE Group\n",
       "14                  TietoEVRY\n",
       "17                Clas Ohlson\n",
       "18                  Softronic\n",
       "19                 Africa Oil\n",
       "20                      Bilia\n",
       "Name: Company, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 1.064682671686621e-09\n",
      "            Iterations: 100001\n",
      "            Function evaluations: 2813918\n",
      "            Gradient evaluations: 100000\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 1.0646826729955636e-09\n",
      "            Iterations: 100001\n",
      "            Function evaluations: 2819358\n",
      "            Gradient evaluations: 100000\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 1.0646825393060503e-09\n",
      "            Iterations: 100001\n",
      "            Function evaluations: 2803583\n",
      "            Gradient evaluations: 100000\n"
     ]
    }
   ],
   "source": [
    "port_tmp = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    N = N_stocks[file_list.index(file)]\n",
    "    data_tmp = pd.read_csv(folder + file)\n",
    "    buy = data_tmp[0:N][['Company','Yahoo' ,'Gestalt Rank', 'Sector']]\n",
    "    \n",
    "    #ONLY KEEP THE HOLD SPREAD FOR THE LAST MONTH? \n",
    "    hold = data_tmp[N: round(SPREAD*N)][['Company','Yahoo', 'Gestalt Rank']] # update to latest month spread??\n",
    "    keep = hold[hold['Company'].isin(current_port)]\n",
    "    \n",
    "    opt_port = pd.concat([buy,keep])\n",
    "    opt_port.loc[: ,'Weight'] = ERC_gestalt(opt_port, lookback=126)\n",
    "    port_tmp = pd.concat([port_tmp,opt_port])\n",
    "    \n",
    "comp_data = port_tmp.drop_duplicates(subset=['Company'])   \n",
    "port_tmp = port_tmp.groupby(['Company']).sum()[['Weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SELL THESE HOLDINGS\n",
    "SELL_LIST =pd.DataFrame(list(set(current_port) - set(port_tmp.index)),columns = ['Company'] )\n",
    "SELL_LIST = SELL_LIST.groupby(['Company']).sum()\n",
    "#Buy these holding\n",
    "BUY_LIST = pd.DataFrame(list(set(port_tmp.index) - set(current_port)),columns = ['Company'])\n",
    "BUY_LIST = BUY_LIST.groupby(['Company']).sum()\n",
    "\n",
    "\n",
    "port_tmp.loc[: ,'Weight'] = (port_tmp['Weight']*100).round(decimals=2)\n",
    "FINAL_PORT = pd.DataFrame(port_tmp['Weight'])\n",
    "FINAL_PORT = FINAL_PORT.sort_values(by = 'Weight', ascending=False)\n",
    "FINAL_PORT['Weight'] = (FINAL_PORT['Weight']/FINAL_PORT['Weight'].sum()).apply(lambda x: round_to_multiple(x, 0.005))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FULL_PORT = pd.concat([SELL_LIST,FINAL_PORT]).merge(rank_data[['Company','Signal', \"Ticker\", \"Yahoo\"]], on = 'Company')\n",
    "FULL_PORT = FULL_PORT.sort_values(by = 'Company', ascending=True)\n",
    "\n",
    "NEW_PORT = FULL_PORT.merge(current_port_tmp[['Company','Antal' ]], on = 'Company', how = 'outer')\n",
    "NEW_PORT.loc[NEW_PORT['Antal'].isna(),'Antal'] = 0\n",
    "NEW_PORT.loc[NEW_PORT['Weight'].isna(),'Weight'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Yahoo</th>\n",
       "      <th>Antal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa Oil</td>\n",
       "      <td>0.050</td>\n",
       "      <td>Buy</td>\n",
       "      <td>AOI</td>\n",
       "      <td>AOI.ST</td>\n",
       "      <td>617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arctic Paper</td>\n",
       "      <td>0.050</td>\n",
       "      <td>Buy</td>\n",
       "      <td>ARP</td>\n",
       "      <td>ARP.ST</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B3 Consulting</td>\n",
       "      <td>0.050</td>\n",
       "      <td>Buy</td>\n",
       "      <td>B3</td>\n",
       "      <td>B3.ST</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BE Group</td>\n",
       "      <td>0.040</td>\n",
       "      <td>Buy</td>\n",
       "      <td>BEGR</td>\n",
       "      <td>BEGR.ST</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Betsson</td>\n",
       "      <td>0.075</td>\n",
       "      <td>Buy</td>\n",
       "      <td>BETS B</td>\n",
       "      <td>BETS-B.ST</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bilia</td>\n",
       "      <td>0.070</td>\n",
       "      <td>Sell</td>\n",
       "      <td>BILI A</td>\n",
       "      <td>BILI-A.ST</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clas Ohlson</td>\n",
       "      <td>0.065</td>\n",
       "      <td>Buy</td>\n",
       "      <td>CLAS B</td>\n",
       "      <td>CLAS-B.ST</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dedicare</td>\n",
       "      <td>0.075</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>DEDI</td>\n",
       "      <td>DEDI.ST</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EnQuest</td>\n",
       "      <td>0.050</td>\n",
       "      <td>Buy</td>\n",
       "      <td>ENQ</td>\n",
       "      <td>ENQ.ST</td>\n",
       "      <td>3479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Petroleum</td>\n",
       "      <td>0.055</td>\n",
       "      <td>Buy</td>\n",
       "      <td>IPCO</td>\n",
       "      <td>IPCO.ST</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New Wave</td>\n",
       "      <td>0.050</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NEWA B</td>\n",
       "      <td>NEWA-B.ST</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nilörngruppen</td>\n",
       "      <td>0.055</td>\n",
       "      <td>Buy</td>\n",
       "      <td>NIL B</td>\n",
       "      <td>NIL-B.ST</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Prevas</td>\n",
       "      <td>0.055</td>\n",
       "      <td>Sell</td>\n",
       "      <td>PREV B</td>\n",
       "      <td>PREV-B.ST</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rottneros</td>\n",
       "      <td>0.055</td>\n",
       "      <td>Buy</td>\n",
       "      <td>RROS</td>\n",
       "      <td>RROS.ST</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSAB B</td>\n",
       "      <td>0.055</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>SSAB B</td>\n",
       "      <td>SSAB-B.ST</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Softronic</td>\n",
       "      <td>0.075</td>\n",
       "      <td>Sell</td>\n",
       "      <td>SOF B</td>\n",
       "      <td>SOF-B.ST</td>\n",
       "      <td>496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TietoEVRY</td>\n",
       "      <td>0.075</td>\n",
       "      <td>Buy</td>\n",
       "      <td>TIETOS</td>\n",
       "      <td>TIETOS.ST</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company  Weight   Signal  Ticker      Yahoo   Antal\n",
       "0                Africa Oil   0.050      Buy     AOI     AOI.ST   617.0\n",
       "1              Arctic Paper   0.050      Buy     ARP     ARP.ST   269.0\n",
       "2             B3 Consulting   0.050      Buy      B3      B3.ST    72.0\n",
       "3                  BE Group   0.040      Buy    BEGR    BEGR.ST    84.0\n",
       "4                   Betsson   0.075      Buy  BETS B  BETS-B.ST   247.0\n",
       "5                     Bilia   0.070     Sell  BILI A  BILI-A.ST    80.0\n",
       "6               Clas Ohlson   0.065      Buy  CLAS B  CLAS-B.ST   174.0\n",
       "7                  Dedicare   0.075  Neutral    DEDI    DEDI.ST   164.0\n",
       "8                   EnQuest   0.050      Buy     ENQ     ENQ.ST  3479.0\n",
       "9   International Petroleum   0.055      Buy    IPCO    IPCO.ST   114.0\n",
       "10                 New Wave   0.050  Neutral  NEWA B  NEWA-B.ST    61.0\n",
       "11            Nilörngruppen   0.055      Buy   NIL B   NIL-B.ST   111.0\n",
       "12                   Prevas   0.055     Sell  PREV B  PREV-B.ST   123.0\n",
       "13                Rottneros   0.055      Buy    RROS    RROS.ST   909.0\n",
       "14                   SSAB B   0.055  Neutral  SSAB B  SSAB-B.ST   242.0\n",
       "15                Softronic   0.075     Sell   SOF B   SOF-B.ST   496.0\n",
       "16                TietoEVRY   0.075      Buy  TIETOS  TIETOS.ST    66.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Björn Borg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kabe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poolia</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Björn Borg, Kabe, Poolia]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELL_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>International Petroleum</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [International Petroleum]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUY_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.DataFrame()\n",
    "for tick in FULL_PORT['Yahoo']:\n",
    "    \n",
    "    price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "    price = price['Adj Close']\n",
    "    prices_df[tick] = price\n",
    "    \n",
    "log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "log_ret = log_ret.dropna() \n",
    "\n",
    "hist_port = log_ret.mul(FULL_PORT['Weight'].values, axis=1).sum(axis = 1).tail(252)\n",
    "\n",
    "prices_df = pd.DataFrame()\n",
    "for tick in [\"^OMX\"]:\n",
    "    \n",
    "    price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "    price = price['Adj Close']\n",
    "    prices_df[tick] = price\n",
    "log_ret_tmp = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "log_ret_tmp = log_ret_tmp.dropna()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = hist_port\n",
    "X = np.array(log_ret_tmp.tail(252))#.reshape(-1, 1)\n",
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_signal = pd.DataFrame([dparser.parse(latest_file,fuzzy=True).strftime(\"%d/%m/%Y\")])\n",
    "date_signal.columns = [\"Date of Signal\"]\n",
    "\n",
    "beta = pd.DataFrame([reg.coef_])\n",
    "beta.columns = [\"Beta to OMX\"]\n",
    "vol = pd.DataFrame([hist_port.tail(60).std() * np.sqrt(252)])\n",
    "vol.columns = [\"Historical Vol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_write = pd.DataFrame([])\n",
    "\n",
    "Zeros =  [0] * N_stocks[0]*2\n",
    "Blanks = [\" \"] * N_stocks[0]*2\n",
    "\n",
    "clean_write.loc[:,'Antal'] = Zeros\n",
    "clean_write.loc[:,'Weight'] = Zeros\n",
    "clean_write.loc[:,'Company'] = Blanks\n",
    "clean_write.loc[:,'Ticker'] = Blanks\n",
    "clean_write.loc[:,'Signal'] = Blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Write to excel file\n",
    "#current_port_tmp\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "book = load_workbook(port_file)\n",
    "writer = pd.ExcelWriter(port_file, engine='openpyxl') \n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "clean_write\n",
    "## CLEAN OLD FILE\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Company'], index = False, startcol = 1)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Ticker'], index = False, startcol = 2)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Antal'], index = False, startcol = 3)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Weight'], index = False, startcol = 4)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Signal'], index = False, startcol = 10)\n",
    "\n",
    "\n",
    "## WRITE NEW PORTFOLIO TO FILE\n",
    "NEW_PORT.to_excel(writer, \"Gestalt\",columns=['Company'], index = False, startcol = 1)\n",
    "NEW_PORT.to_excel(writer, \"Gestalt\",columns=['Ticker'], index = False, startcol = 2)\n",
    "NEW_PORT.to_excel(writer, \"Gestalt\",columns=['Antal'], index = False, startcol = 3)\n",
    "NEW_PORT.to_excel(writer, \"Gestalt\",columns=['Weight'], index = False, startcol = 4)\n",
    "NEW_PORT.to_excel(writer, \"Gestalt\",columns=['Signal'], index = False, startcol = 10)\n",
    "\n",
    "\n",
    "date_signal.to_excel(writer, \"Gestalt\", index = False, startcol = 10, startrow=N_stocks[0]*2 +1)\n",
    "beta.to_excel(writer, \"Gestalt\", index = False, startcol = 11, startrow=N_stocks[0]*2 +1)\n",
    "vol.to_excel(writer, \"Gestalt\", index = False, startcol = 12, startrow=N_stocks[0]*2 +1)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### EXPERIMENT ###################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
