{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import pandas as pd\n",
    "import yfinance as yf \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from scipy.stats import norm\n",
    "import ezodf\n",
    "import scipy.optimize as sco\n",
    "import scipy\n",
    "\n",
    "from sklearn.covariance import LedoitWolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimize_Portfolio(data ,risk_free = 0, objective = 'Kelly'):\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if objective == 'Kelly':  \n",
    "        #ret = (data).prod()**(1/len(data)) - 1 #cagr\n",
    "        ret = (data-1).mean()\n",
    "        #cov = data.cov().to_numpy()\n",
    "        cov_fit = LedoitWolf().fit(data)\n",
    "        cov = cov_fit.covariance_\n",
    "        \n",
    "        #need smaller step size\n",
    "        num_assets = ret.shape[0]\n",
    "        args = (ret, cov,risk_free)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                      {'type':'ineq', 'fun': lambda x: 1 - np.sum(x)}) # sum <= 1\n",
    "                      #{'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  \n",
    "        \n",
    "        \n",
    "        result = sco.minimize(kelly_objective, num_assets*[1./num_assets,], args=args, \n",
    "                                  method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001) \n",
    "        \n",
    "    elif objective == 'Sharpe':\n",
    "        ret = (data-1).mean() \n",
    "      \n",
    "        cov_fit = LedoitWolf().fit(data)\n",
    "        cov = cov_fit.covariance_\n",
    "        \n",
    "        num_assets = ret.shape[0]\n",
    "        args = (ret, cov,risk_free)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  \n",
    "        result = sco.minimize(sharpe_objective, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "    \n",
    "    elif objective == 'Max Div':\n",
    "        num_assets = len(data.columns)\n",
    "        #cov = data.cov().to_numpy()\n",
    "        \n",
    "        cov_fit = LedoitWolf().fit(data)\n",
    "        cov = cov_fit.covariance_\n",
    "        \n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(calc_diversification_ratio, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "    elif objective == \"min var\":\n",
    "        num_assets = len(data.columns)\n",
    "        \n",
    "        \n",
    "        cov_fit = LedoitWolf().fit(data)\n",
    "        cov = cov_fit.covariance_\n",
    "        \n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(port_var, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "    elif objective == \"erc\":\n",
    "        num_assets = len(data.columns)\n",
    "        #cov = data.cov().to_numpy()\n",
    "        \n",
    "        cov_fit = LedoitWolf().fit(data)\n",
    "        cov = cov_fit.covariance_\n",
    "        \n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(erc, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    return (result)\n",
    "\n",
    "def kelly_objective(weights,ret, cov, risk_free = 0):\n",
    "    \n",
    "    #kelly_ret = port_ret(weights, ret)\n",
    "    kelly_ret = port_ret(weights, ret) - port_var(weights, cov)/2\n",
    "    \n",
    "    obj = -(kelly_ret)\n",
    "    \n",
    "    return(obj)\n",
    "\n",
    "def sharpe_objective(weights,ret, cov, risk_free = 0):\n",
    "    ret = port_ret(weights, ret)\n",
    "    std = port_var(weights, cov)**(1/2)\n",
    "    \n",
    "    obj = - (ret/std)\n",
    "    return(obj)\n",
    "\n",
    "\n",
    "def port_var(weights, cov):\n",
    "    var = weights.dot(cov).dot(weights)\n",
    "    return(var)\n",
    "\n",
    "def port_ret(weights, ret, risk_free = 0):\n",
    "    #needs to be array\n",
    "    ret = ret - risk_free\n",
    "    port_ret = weights.dot(ret)\n",
    "    return(port_ret)\n",
    "\n",
    "def risk_parity(data):\n",
    "    vol = np.log((data)).std()\n",
    "\n",
    "    sum_vol = 0\n",
    "    for i in range(len(vol)):\n",
    "        sum_vol =sum_vol + (1/vol[i])\n",
    "    \n",
    "    weight = []\n",
    "    for i in range(len(vol)):\n",
    "        w = (1/vol[i])/(sum_vol)\n",
    "        weight.append(w)\n",
    "   \n",
    "    weight = [round(num, 2) for num in weight]\n",
    "    return(weight)\n",
    "\n",
    "\n",
    "def calc_diversification_ratio(weights, cov):\n",
    "    # average weighted vol\n",
    "    w_vol = np.dot(np.sqrt(np.diag(cov)), weights.T)\n",
    "    # portfolio vol\n",
    "    port_vol = np.sqrt(port_var(weights, cov))\n",
    "    \n",
    "    diversification_ratio = w_vol/port_vol\n",
    "    # return negative for minimization problem (maximize = minimize -)\n",
    "    return -diversification_ratio\n",
    "\n",
    "def erc(weights, cov):\n",
    "        # these are non normalized risk contributions, i.e. not regularized\n",
    "        # by total risk, seems to help numerically\n",
    "        risk_contributions = np.dot(weights, cov) * weights\n",
    "        a = np.reshape(risk_contributions, (len(risk_contributions), 1))\n",
    "        # broadcasts so you get pairwise differences in risk contributions\n",
    "        risk_diffs = a - a.transpose()\n",
    "        sum_risk_diffs_squared = np.sum(np.square(np.ravel(risk_diffs)))\n",
    "        # https://stackoverflow.com/a/36685019/1451311\n",
    "        return sum_risk_diffs_squared #/ scale_factorcov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA analysis for momentum portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tickers = ['SBB-B.ST', 'NP3.ST', 'TRANS.ST', 'NOTE.ST', 'LIAB.ST', 'HANZA.ST', 'SECT-B.ST',\n",
    " #          'ALCA.ST', 'NYF.ST', 'THULE.ST']\n",
    "\n",
    "tickers = ['GLD', 'TLT', 'SPY']\n",
    "\n",
    "PCS_n = len(tickers) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.DataFrame()\n",
    "\n",
    "for tick in tickers:\n",
    "    \n",
    "    price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "    price = price['Close']\n",
    "    prices_df[tick] = price\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_ret = prices_df.pct_change()\n",
    "stocks_ret = stocks_ret[1:] # skip the first row (NaN)\n",
    "stocks_ret = stocks_ret.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_ret = stocks_ret.resample('m').last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load strategy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =  \"strategy_returns.csv\"\n",
    "folder = \"/Users/erikhermansson/Projects/Python_Proj/Finance/SISU_CAPITAL/Backtest/Project_Coeus/data/\"\n",
    "data_tmp = pd.read_csv(folder + file_name)\n",
    "data_tmp['d'] = pd.to_datetime(data_tmp['d'])\n",
    "data_tmp = data_tmp.set_index(['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stocks_ret = pd.concat([data_tmp,stocks_ret], axis= 1)\n",
    "stocks_ret = data_tmp\n",
    "stocks_ret = stocks_ret.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCS_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6285e54ec785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# USING SKLEARN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msklearn_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearnPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCS_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# let's look at the first 20 components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCS_n' is not defined"
     ]
    }
   ],
   "source": [
    "stocks_cov = stocks_ret.cov()\n",
    "\n",
    "# USING SKLEARN\n",
    "sklearn_pca = sklearnPCA(n_components=PCS_n) # let's look at the first 20 components\n",
    "pc = sklearn_pca.fit_transform(stocks_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCS_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f53609c30efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the variance explained by pcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPCS_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msklearn_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variance explained by pc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCS_n' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the variance explained by pcs\n",
    "plt.bar(range(PCS_n),sklearn_pca.explained_variance_ratio_)\n",
    "plt.title('variance explained by pc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a6517b587328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check the explained variance reatio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get the Principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpcs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msklearn_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn_pca' is not defined"
     ]
    }
   ],
   "source": [
    "# check the explained variance reatio\n",
    "print(sklearn_pca.explained_variance_ratio_)\n",
    "\n",
    "# get the Principal components\n",
    "pcs =sklearn_pca.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimazation Method: Sharpe\n",
      "[ 0.13 -0.   -0.    0.52  0.35 -0.  ] \n",
      "\n",
      "Optimazation Method: Kelly\n",
      "[ 0.31 -0.   -0.   -0.    0.69 -0.  ] \n",
      "\n",
      "Optimazation Method: Max Div\n",
      "[0.17 0.08 0.16 0.11 0.17 0.32] \n",
      "\n",
      "Optimazation Method: min var\n",
      "[-0.    0.   -0.    0.4   0.07  0.53] \n",
      "\n",
      "Optimazation Method: erc\n",
      "[0.13 0.13 0.17 0.19 0.15 0.23] \n",
      "\n",
      "Optimazation Method: Risk Parity\n",
      "[0.13, 0.14, 0.16, 0.21, 0.15, 0.21]\n"
     ]
    }
   ],
   "source": [
    "data = stocks_ret+1\n",
    "for obj in ['Sharpe', 'Kelly', 'Max Div', \"min var\", 'erc']:\n",
    "    print('Optimazation Method:', obj)\n",
    "    result = Optimize_Portfolio(data, objective=obj)\n",
    "    print(result['x'].round(2), \"\\n\")\n",
    "\n",
    "print(\"Optimazation Method: Risk Parity\")\n",
    "print(risk_parity(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comb_mom_rank', 'ear_mom_rank', 'EAR_std_rank', 'focus_mom_rank',\n",
       "       'VMQ_rank', 'Benchmark'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimazation Method: Sharpe\n",
      "[ 0.13 -0.   -0.    0.52  0.35 -0.  ] \n",
      "\n",
      "Optimazation Method: Kelly\n",
      "[ 0.31 -0.   -0.   -0.    0.69 -0.  ] \n",
      "\n",
      "Optimazation Method: Max Div\n",
      "[0.17 0.08 0.16 0.11 0.17 0.32] \n",
      "\n",
      "Optimazation Method: min var\n",
      "[-0.    0.   -0.    0.4   0.07  0.53] \n",
      "\n",
      "Optimazation Method: erc\n",
      "[0.13 0.13 0.17 0.19 0.15 0.23] \n",
      "\n",
      "Optimazation Method: Risk Parity\n",
      "[0.13, 0.14, 0.16, 0.21, 0.15, 0.21]\n"
     ]
    }
   ],
   "source": [
    "data = stocks_ret+1\n",
    "for obj in ['Sharpe', 'Kelly', 'Max Div', \"min var\", 'erc']:\n",
    "    print('Optimazation Method:', obj)\n",
    "    result = Optimize_Portfolio(data, objective=obj)\n",
    "    print(result['x'].round(2), \"\\n\")\n",
    "\n",
    "print(\"Optimazation Method: Risk Parity\")\n",
    "print(risk_parity(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
