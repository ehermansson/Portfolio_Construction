{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import sys\n",
    "import re\n",
    "import os.path\n",
    "import yfinance as yf \n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats.mstats import winsorize\n",
    "import os\n",
    "import glob\n",
    "import dateutil.parser as dparser\n",
    "\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Ledoit & Wolf constant correlation unequal variance shrinkage estimator.\"\"\"\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "def shrinkage(returns: np.array) -> Tuple[np.array, float, float]:\n",
    "    \"\"\"Shrinks sample covariance matrix towards constant correlation unequal variance matrix.\n",
    "    Ledoit & Wolf (\"Honey, I shrunk the sample covariance matrix\", Portfolio Management, 30(2004),\n",
    "    110-119) optimal asymptotic shrinkage between 0 (sample covariance matrix) and 1 (constant\n",
    "    sample average correlation unequal sample variance matrix).\n",
    "    Paper:\n",
    "    http://www.ledoit.net/honey.pdf\n",
    "    Matlab code:\n",
    "    https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-ffff-ffffde5e2d4e/covCor.m.zip\n",
    "    Special thanks to Evgeny Pogrebnyak https://github.com/epogrebnyak\n",
    "    :param returns:\n",
    "        t, n - returns of t observations of n shares.\n",
    "    :return:\n",
    "        Covariance matrix, sample average correlation, shrinkage.\n",
    "    \"\"\"\n",
    "    t, n = returns.shape\n",
    "    mean_returns = np.mean(returns, axis=0, keepdims=True)\n",
    "    returns -= mean_returns\n",
    "    sample_cov = returns.transpose() @ returns / t\n",
    "\n",
    "    # sample average correlation\n",
    "    var = np.diag(sample_cov).reshape(-1, 1)\n",
    "    sqrt_var = var ** 0.5\n",
    "    unit_cor_var = sqrt_var * sqrt_var.transpose()\n",
    "    average_cor = ((sample_cov / unit_cor_var).sum() - n) / n / (n - 1)\n",
    "    prior = average_cor * unit_cor_var\n",
    "    np.fill_diagonal(prior, var)\n",
    "\n",
    "    # pi-hat\n",
    "    y = returns ** 2\n",
    "    phi_mat = (y.transpose() @ y) / t - sample_cov ** 2\n",
    "    phi = phi_mat.sum()\n",
    "\n",
    "    # rho-hat\n",
    "    theta_mat = ((returns ** 3).transpose() @ returns) / t - var * sample_cov\n",
    "    np.fill_diagonal(theta_mat, 0)\n",
    "    rho = (\n",
    "        np.diag(phi_mat).sum()\n",
    "        + average_cor * (1 / sqrt_var @ sqrt_var.transpose() * theta_mat).sum()\n",
    "    )\n",
    "\n",
    "    # gamma-hat\n",
    "    gamma = np.linalg.norm(sample_cov - prior, \"fro\") ** 2\n",
    "\n",
    "    # shrinkage constant\n",
    "    kappa = (phi - rho) / gamma\n",
    "    shrink = max(0, min(1, kappa / t))\n",
    "\n",
    "    # estimator\n",
    "    sigma = shrink * prior + (1 - shrink) * sample_cov\n",
    "\n",
    "    return sigma, average_cor, shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkage_EMW(returns_tmp: np.array, lookback = 126) -> Tuple[np.array, float, float]:\n",
    "    \"\"\"Shrinks sample covariance matrix towards constant correlation unequal variance matrix.\n",
    "    Ledoit & Wolf (\"Honey, I shrunk the sample covariance matrix\", Portfolio Management, 30(2004),\n",
    "    110-119) optimal asymptotic shrinkage between 0 (sample covariance matrix) and 1 (constant\n",
    "    sample average correlation unequal sample variance matrix).\n",
    "    Paper:\n",
    "    http://www.ledoit.net/honey.pdf\n",
    "    Matlab code:\n",
    "    https://www.econ.uzh.ch/dam/jcr:ffffffff-935a-b0d6-ffff-ffffde5e2d4e/covCor.m.zip\n",
    "    Special thanks to Evgeny Pogrebnyak https://github.com/epogrebnyak\n",
    "    :param returns:\n",
    "        t, n - returns of t observations of n shares.\n",
    "    :return:\n",
    "        Covariance matrix, sample average correlation, shrinkage.\n",
    "    \"\"\"\n",
    "    returns = returns_tmp.tail(lookback).values\n",
    "    t, n = returns.shape\n",
    "    mean_returns = np.mean(returns, axis=0, keepdims=True) # make EWMA\n",
    "    returns -= mean_returns\n",
    "    COV_tmp = returns_tmp.ewm(span = lookback).cov()\n",
    "    idx = returns_tmp.index.get_level_values(0)[-1]\n",
    "    sample_cov = COV_tmp[COV_tmp.index.get_level_values(0) == idx]\n",
    "    sample_cov = sample_cov.values\n",
    "    #sample_cov = returns.transpose() @ returns / t\n",
    "\n",
    "    # sample average correlation\n",
    "    var = np.diag(sample_cov).reshape(-1, 1)\n",
    "    sqrt_var = var ** 0.5\n",
    "    unit_cor_var = sqrt_var * sqrt_var.transpose()\n",
    "    average_cor = ((sample_cov / unit_cor_var).sum() - n) / n / (n - 1)\n",
    "    prior = average_cor * unit_cor_var\n",
    "    np.fill_diagonal(prior, var)\n",
    "\n",
    "    # pi-hat\n",
    "    y = returns ** 2\n",
    "    phi_mat = (y.transpose() @ y) / t - sample_cov ** 2\n",
    "    phi = phi_mat.sum()\n",
    "\n",
    "    # rho-hat\n",
    "    theta_mat = ((returns ** 3).transpose() @ returns) / t - var * sample_cov\n",
    "    np.fill_diagonal(theta_mat, 0)\n",
    "    rho = (\n",
    "        np.diag(phi_mat).sum()\n",
    "        + average_cor * (1 / sqrt_var @ sqrt_var.transpose() * theta_mat).sum()\n",
    "    )\n",
    "\n",
    "    # gamma-hat\n",
    "    gamma = np.linalg.norm(sample_cov - prior, \"fro\") ** 2\n",
    "\n",
    "    # shrinkage constant\n",
    "    kappa = (phi - rho) / gamma\n",
    "    shrink = max(0, min(1, kappa / t))\n",
    "\n",
    "    # estimator\n",
    "    sigma = shrink * prior + (1 - shrink) * sample_cov\n",
    "\n",
    "    return sigma, average_cor, shrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import ezodf\n",
    "import scipy.optimize as sco\n",
    "import scipy\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "def Optimize_Portfolio(data ,lookback = 126, risk_free = 0, objective = 'Kelly'):\n",
    "\n",
    "    ret = (data-1).mean()\n",
    "    #cov_fit = LedoitWolf().fit(data)\n",
    "    #cov = cov_fit.covariance_\n",
    "    cov, average_cor, shrink = shrinkage_EMW(data, lookback = lookback)\n",
    "    #cov = PCA_cov(data, N=5)\n",
    "   \n",
    "  \n",
    "    if objective == 'Max Div':\n",
    "        num_assets = len(data.columns)\n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(calc_diversification_ratio, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "    elif objective == \"min var\":\n",
    "        num_assets = len(data.columns)\n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) \n",
    "        \n",
    "        result = sco.minimize(port_var, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "    elif objective == \"erc\":\n",
    "        num_assets = len(data.columns) \n",
    "        args = (cov)\n",
    "        constraints = ({'type':'ineq', 'fun': lambda x: x},#all elements greater than one\n",
    "                  #{'type':'ineq', 'fun': lambda x: 1 - np.sum(x)} # sum <= 1\n",
    "                  {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
    "                      {'type':'ineq', 'fun': lambda x: x-(1/num_assets)*0.7}, # min position\n",
    "                      {'type':'ineq', 'fun': lambda x: (1/num_assets)*1.3-x}) # max position\n",
    "        \n",
    "        result = sco.minimize(erc, num_assets*[1./num_assets,], args=args, \n",
    "                              method='SLSQP', constraints=constraints, tol = 0.0000000000000000000000001)\n",
    "        \n",
    "\n",
    "    return (result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def port_var(weights, cov):\n",
    "    var = weights.dot(cov).dot(weights)\n",
    "    return(var)\n",
    "\n",
    "def port_ret(weights, ret, risk_free = 0):\n",
    "    #needs to be array\n",
    "    ret = ret - risk_free\n",
    "    port_ret = weights.dot(ret)\n",
    "    return(port_ret)\n",
    "\n",
    "def risk_parity(data):\n",
    "    vol = np.log((data)).std()\n",
    "\n",
    "    sum_vol = 0\n",
    "    for i in range(len(vol)):\n",
    "        sum_vol =sum_vol + (1/vol[i])\n",
    "    \n",
    "    weight = []\n",
    "    for i in range(len(vol)):\n",
    "        w = (1/vol[i])/(sum_vol)\n",
    "        weight.append(w)\n",
    "   \n",
    "    weight = [round(num, 2) for num in weight]\n",
    "    return(weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_diversification_ratio(weights, cov):\n",
    "    # average weighted vol\n",
    "    w_vol = np.dot(np.sqrt(np.diag(cov)), weights.T)\n",
    "    # portfolio vol\n",
    "    port_vol = np.sqrt(port_var(weights, cov))\n",
    "    \n",
    "    diversification_ratio = w_vol/port_vol\n",
    "    # return negative for minimization problem (maximize = minimize -)\n",
    "    return -diversification_ratio\n",
    "\n",
    "def erc(weights, cov):\n",
    "        # these are non normalized risk contributions, i.e. not regularized\n",
    "        # by total risk, seems to help numerically\n",
    "        risk_contributions = np.dot(weights, cov) * weights\n",
    "        a = np.reshape(risk_contributions, (len(risk_contributions), 1))\n",
    "        # broadcasts so you get pairwise differences in risk contributions\n",
    "        risk_diffs = a - a.transpose()\n",
    "        sum_risk_diffs_squared = np.sum(np.square(np.ravel(risk_diffs)))\n",
    "        # https://stackoverflow.com/a/36685019/1451311\n",
    "        return sum_risk_diffs_squared #/ scale_factorcov\n",
    "    \n",
    "\n",
    "\n",
    "import sklearn.datasets, sklearn.decomposition\n",
    "\n",
    "def PCA_cov(data, N = 5):\n",
    "    \n",
    "    X = data.ewm(span = 252).cov()\n",
    "    DATE_IDX = X.index.get_level_values(level=0)[-1]\n",
    "    X = X[X.index.get_level_values(0)==DATE_IDX].droplevel(0)\n",
    "    mu = np.mean(X, axis=0)\n",
    "\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca.fit(X)\n",
    "\n",
    "    nComp = N\n",
    "    Xhat = np.dot(pca.transform(X)[:,:nComp], pca.components_[:nComp,:])\n",
    "    Xhat += mu\n",
    "    clean_cov = pd.DataFrame(Xhat)\n",
    "    clean_cov.index = X.index\n",
    "    clean_cov.columns = X.index\n",
    "    return(clean_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERC_gestalt(data, lookback = 126):\n",
    "    \n",
    "    prices_df = pd.DataFrame()\n",
    "    for tick in data['Yahoo']:\n",
    "    \n",
    "        price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "        price = price['Adj Close']\n",
    "        prices_df[tick] = price\n",
    "    \n",
    "    log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "    log_ret = log_ret.dropna()\n",
    "    weight = Optimize_Portfolio(log_ret, lookback = lookback, objective='erc')['x'].round(3)\n",
    "\n",
    "    return(weight)\n",
    "\n",
    "def round_to_multiple(number, multiple):\n",
    "    return multiple * round(number / multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import old portfolios to construct staggerd portfolio\n",
    "\n",
    "- Q: How to handel \"hold\" positions?\n",
    "- \"Hold\" companies shold have \"Min Position\" == ACTION/3 rest is weighted from this? and MAX = Average posiotn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 332/482 [01:50<00:39,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- SDIP.ST: No data found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [02:40<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "### Settings\n",
    "START_DATE = '2016-01-01'\n",
    "error_count = 0\n",
    "error_list = []\n",
    "\n",
    "\n",
    "latest_file= max(glob.glob(\"../equity_data/*.*\"), key=os.path.getmtime)\n",
    "\n",
    "signal_df = pd.read_excel(latest_file, sheet_name=\"Export\")\n",
    "signal_df = signal_df.rename({'Performance - Perform. 3m' : 'Return 3m','Performance - Perform. 6m' : 'Return 6m',\n",
    "                            'Total Return - Return 1y' : 'Return 1y',\n",
    "                            'Div. Yield - Current': 'Yield',\n",
    "                            'Total Equity  - Millions':'Total Equity', 'FCF - Millions': 'FCF','ROE - Current':'ROE',\n",
    "                            'Volatility - St.Dev. 100d':'Volatility','Market Cap - Current': 'Market Cap', \n",
    "                            'ROC - Current':'ROC', 'Tot. Assets - Millions':'Tot. Assets', \n",
    "                            'Gross profit - Millions':'Gross profit', 'Assets Turn - Current': 'Assets Turn',\n",
    "                            'P/FCF - Current':'P/FCF', 'P/E - Current':'P/E', 'P/S - Current':'P/S',\n",
    "                            'P/B - Current':'P/B','EV/EBIT - Current':'EV/EBIT',\n",
    "                            'Info - Country' : 'Country','F-Score - Point':'F-Score',\n",
    "                            'Info - List' : 'List', 'Info - Sector' : 'Sector', 'Info - Industry' : 'Industry',\n",
    "                            'Info - Ticker' : 'Ticker', 'Info - Yahoo':'Yahoo', 'Info - Last Report': 'Last Report',\n",
    "                           'Volume - Average 50d Mill' : 'Volume', 'Tot. Assets - Growth 1y' : 'Asset Growth'}, axis=1)\n",
    "\n",
    "\n",
    "signal_df = signal_df.loc[ (signal_df['List'] != 'Spotlight') \n",
    "                        & (signal_df['List'] != 'NGM') & (signal_df['Country'] == \"Sweden\") &\n",
    "                         (signal_df['Market Cap'] > 200)]\n",
    "\n",
    "signal_df = signal_df.loc[(signal_df['Sector'] != 'Financials')]\n",
    "\n",
    "# Set to dattime\n",
    "signal_df['Last Report'] = pd.to_datetime(signal_df['Last Report'])\n",
    "#set new index\n",
    "signal_df.index = range(len(signal_df.index))\n",
    "\n",
    "\n",
    "signal_df['Res_Mom_1M'] = np.nan\n",
    "signal_df['Res_Mom_1M_alt'] = np.nan\n",
    "\n",
    "signal_df['Tot_Mom_1M'] = np.nan\n",
    "signal_df['Sea_month_5yr'] = np.nan\n",
    "signal_df['idio_vol_20day'] = np.nan\n",
    "signal_df['maxret_5days'] = np.nan\n",
    "signal_df[\"EAR_std\"]= np.nan\n",
    "signal_df[\"5yr_vol\"]= np.nan\n",
    "signal_df[\"liq_shock\"]= np.nan\n",
    "\n",
    "index = yf.download('^OMXSPI',start=START_DATE, threads = False, progress = False)\n",
    "index = index['Adj Close']\n",
    "for i in tqdm(range(len(signal_df))):\n",
    "\n",
    "    try:\n",
    "        stock_tmp = yf.download(signal_df.iloc[i]['Yahoo'],start=START_DATE, progress = False, threads = False)\n",
    "\n",
    "        \n",
    "        stock = stock_tmp['Adj Close']\n",
    "        import_data = pd.concat([stock, index], axis = 1)\n",
    "        import_data.columns = ['stock', 'index']\n",
    "        import_data = import_data.dropna()\n",
    "        \n",
    "        long_df = import_data.copy()\n",
    "        ret_df = np.log(import_data/import_data.shift()).dropna()\n",
    "        ### SEASONALITY\n",
    "        \n",
    "        monthly_df = import_data.resample('M').last()\n",
    "        monthly_ret_df = np.log(monthly_df/monthly_df.shift()).dropna()\n",
    "         \n",
    "        ### 1 Month Momentum\n",
    "        signal_df.loc[i,\"Tot_Mom_1M\"] = ret_df['stock'].tail(21).sum()\n",
    "        \n",
    "        \n",
    "        ##EAR\n",
    "        idx = ret_df.index.get_loc(signal_df.iloc[i]['Last Report'], method='nearest')\n",
    "        \n",
    "        EA_data = import_data.iloc[idx - 2 : idx +2 ]\n",
    "        \n",
    "        EA_ret = (EA_data.pct_change().dropna()+1).cumprod().tail(1)\n",
    "        pead_ret = float(EA_ret['stock'] - EA_ret['index']) #Should use np.log()\n",
    "        pead_vol = np.log(stock.iloc[:idx]/stock.iloc[:idx].shift()).tail(60).std()*252**.5\n",
    "        signal_df.loc[i, 'EAR_std'] = pead_ret/pead_vol\n",
    "        \n",
    "        ## liquidity shock\n",
    "        \n",
    "        stock_volume = stock_tmp.copy()\n",
    "        stock_volume['volume_sek'] = stock_volume['Close'] *stock_volume['Volume']\n",
    "        \n",
    "        # Resample to monthly for sobustness???\n",
    "        stock_volume = stock_volume.rolling(21).sum().resample('30D').last()\n",
    "        \n",
    "\n",
    "        liq_shock = (stock_volume['volume_sek'].tail(1) - stock_volume['volume_sek'].tail(12).mean())/stock_volume['volume_sek'].tail(12).std()\n",
    "        signal_df.loc[i,\"liq_shock\"] = float(liq_shock)\n",
    "        \n",
    "        ### RESIDUAL MOMENTUM\n",
    "        ret_trim_df = ret_df.drop(ret_df.iloc[[idx - 1, idx, idx +1, idx +2 ]].index)\n",
    "        \n",
    "        \n",
    "        signal_df.loc[i,\"maxret_5days\"] = np.mean(sorted(ret_trim_df['stock'].tail(21))[-5:])\n",
    "        y_res = ret_trim_df.tail(21)['stock']\n",
    "        X_res = np.array(ret_trim_df.tail(21)['index']).reshape(-1, 1)\n",
    "        reg_res = LinearRegression().fit(X_res, y_res)\n",
    "        residuals_res = y_res - reg_res.predict(X_res)\n",
    "        signal_df.loc[i,\"idio_vol_20day\"] = residuals_res.std()\n",
    "        \n",
    "        #volume weight for short term rev\n",
    "        vol_weight_tmp = stock_tmp.copy()\n",
    "        vol_weight_tmp['volume_sek'] = vol_weight_tmp['Close'] *vol_weight_tmp['Volume']\n",
    "        #weight by 60 day MA\n",
    "        vol_weight = vol_weight_tmp['volume_sek'].rolling(252).mean() / vol_weight_tmp['volume_sek']\n",
    "        \n",
    "        reg_df = ret_trim_df.tail(3*252)\n",
    "        ## Identify Report \n",
    "        if len(reg_df)>(2*252):\n",
    "            y = reg_df['stock']\n",
    "            X = np.array(reg_df['index']).reshape(-1, 1)\n",
    "            reg = LinearRegression().fit(X, y)\n",
    "            beta = reg.coef_[0]\n",
    "            residuals = y - reg.predict(X)\n",
    "            std_residuals = residuals/residuals.std()\n",
    "            \n",
    "            signal_df.loc[i,\"Res_Mom_1M\"] = std_residuals.tail(21).sum()# + np.log(vol_weight.tail(21)).sum()\n",
    "           \n",
    "        \n",
    "        if len(monthly_ret_df)>=36:\n",
    "            seas_list = []\n",
    "            monthly_vol = 0\n",
    "            for look in [12,24,36,48,60]:\n",
    "                try:\n",
    "                    seas_list.append(monthly_ret_df['stock'].iloc[-look])\n",
    "                    monthly_vol = (monthly_ret_df['stock'].tail(60)+1).std() * np.sqrt(12)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "            signal_df.loc[i,\"Sea_month_5yr\"] = np.mean(seas_list) *12\n",
    "            signal_df.loc[i,\"5yr_vol\"] = monthly_vol\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        error_count = error_count + 1\n",
    "        error_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../equity_data/Borsdata_2022-08-27.xlsx'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### CREATE NEW SECTORS!\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Leisure', 'Gambling & Casinos','Airlines','Hotels']),'Sector'] = 'Travel & Leisure'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Pharmaceuticals']),'Sector'] = 'Pharmaceuticals'\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Medical Equipment']),'Sector'] = 'Medical Equipment'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Retailers','Auto & Equipment','Industrial Components', 'Clothing & Footwear',\n",
    "    'Consumer Electronics', 'Accessories' ]),'Sector'] = 'Retail'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['IT Consulting', 'IT Services', 'Communications',]),'Sector'] = 'Software'\n",
    "\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Industrial Components',\n",
    "    'Energy & Recycling' ]),'Sector'] = 'General Industrials'\n",
    "\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Construction Supplies','Construction & Infrastructure',\n",
    "     'Installation']),'Sector'] = 'Construction & Materials' \n",
    "\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Industrial Machinery', 'Electrical Components']),'Sector'] = 'Electronic & Electrical Equipment'\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Holding Companies']),'Sector'] = 'Holding Companies'\n",
    "\n",
    "\n",
    "signal_df.loc[signal_df['Industry'].isin(\n",
    "    ['Real Estate']),'Sector'] = 'Real Estate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CUTOFF = 0.33 #0.25 # which cut off??\n",
    "\n",
    "method = 'median'\n",
    "\n",
    "### SHORT TERM REVERSAL - adjust for industry ###\n",
    "signal_df['Res_Mom_1M_adj'] = signal_df[\"Res_Mom_1M\"] - signal_df.groupby(\"Sector\")[\"Res_Mom_1M\"].transform(method)\n",
    "\n",
    "\n",
    "#Vol adjsuted Seasonality\n",
    "signal_df['Sea_month_5yr_std'] = signal_df['Sea_month_5yr']/signal_df['5yr_vol']\n",
    "\n",
    "### IVOL - adjust for industry\n",
    "signal_df['idio_vol_20day_adj'] = signal_df[\"idio_vol_20day\"] - signal_df.groupby(\"Sector\")[\"idio_vol_20day\"].transform(method)\n",
    "\n",
    "## MAX RET - adjust for industry\n",
    "signal_df['maxret_5days_adj'] = signal_df[\"maxret_5days\"] - signal_df.groupby(\"Sector\")[\"maxret_5days\"].transform(method)\n",
    "\n",
    "########## INDUSTRY MOMENTUM ASSNESS SHOWS THAT EQUAL WEIGHT WORKS\n",
    "signal_df['Sector Weighted Mom'] = signal_df.groupby(\"Sector\")[\"Tot_Mom_1M\"].transform(method)\n",
    "\n",
    "# IMPUTE MEDIAN VALUE FOR NANS\n",
    "signal_df['Res_Mom_1M_adj'] = signal_df['Res_Mom_1M_adj'].fillna(signal_df['Res_Mom_1M'].median())\n",
    "\n",
    "### SEASONALITY\n",
    "signal_df['Sea_month_5yr_std'] = signal_df['Sea_month_5yr_std'].fillna(signal_df['Sea_month_5yr_std'].median())\n",
    "### SHORT TERM IVOL\n",
    "signal_df['idio_vol_20day_adj'] = signal_df['idio_vol_20day_adj'].fillna(signal_df['idio_vol_20day'].median())\n",
    "### MAX RET\n",
    "signal_df['maxret_5days_adj'] = signal_df['maxret_5days_adj'].fillna(signal_df['maxret_5days_adj'].median())\n",
    "# Ear \n",
    "signal_df['EAR_std'] = signal_df['EAR_std'].fillna(signal_df['EAR_std'].median())\n",
    "# Liquidity Shock\n",
    "signal_df['liq_shock'] = signal_df['liq_shock'].fillna(signal_df['liq_shock'].median())\n",
    "\n",
    "\n",
    "\n",
    "######### RANK ON INDIVIDUAL PREDICTORS\n",
    "signal_df['Res_Mom_1M_adj_rank'] = signal_df['Res_Mom_1M_adj'].rank(ascending=True, pct = True)\n",
    "#high is good\n",
    "signal_df['Sector Momentum Rank'] =  signal_df['Sector Weighted Mom'].rank(ascending=False, pct = True)\n",
    "#high is good\n",
    "signal_df['Seasonality Rank'] =  signal_df['Sea_month_5yr'].rank(ascending=False, pct = True)\n",
    "#high is good\n",
    "signal_df['Seasonality Rank Std'] =  signal_df['Sea_month_5yr_std'].rank(ascending=False, pct = True)\n",
    "#low is good\n",
    "signal_df['IVOL_adj Rank'] =  signal_df['idio_vol_20day_adj'].rank(ascending=True, pct = True)\n",
    "#low is good\n",
    "signal_df['MAXRET_adj Rank'] =  signal_df['maxret_5days_adj'].rank(ascending=True, pct = True)\n",
    "#high is good\n",
    "signal_df['EAR_std Rank'] =  signal_df['EAR_std'].rank(ascending=False, pct = True)\n",
    "#high is good\n",
    "signal_df['liq_shock Rank'] =  signal_df['liq_shock'].rank(ascending=False, pct = True)\n",
    "\n",
    "################# YOU WANT THE LOWEST SCORE POSSIBLE\n",
    "## USE PCT. \n",
    "## Implement an interaction score for liquidity and SREV \n",
    "\n",
    "signal_df['High_Freq_Combo'] = ( signal_df['Sector Momentum Rank'] +\n",
    "                               signal_df['Res_Mom_1M_adj_rank'] +\n",
    "                               signal_df['Seasonality Rank Std'] +  signal_df['EAR_std Rank'] +\n",
    "                                signal_df['liq_shock Rank']+\n",
    "                                0.5*signal_df['IVOL_adj Rank'] + 0.5*signal_df['MAXRET_adj Rank']\n",
    "                                ).rank(ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "signal_df['Signal'] = \"Neutral\"\n",
    "idx_BUY = signal_df['High_Freq_Combo']<=signal_df['High_Freq_Combo'].quantile(CUTOFF)\n",
    "signal_df.loc[idx_BUY,'Signal']= 'Buy'\n",
    "\n",
    "\n",
    "idx_SELL = signal_df['High_Freq_Combo']>=signal_df['High_Freq_Combo'].quantile(1-CUTOFF)\n",
    "signal_df.loc[idx_SELL,'Signal'] = 'Sell'\n",
    "rank_data = signal_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIMIZE PORTFOLIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hvol_yz(df, lookback=10):\n",
    "    o = df.Open\n",
    "    h = df.High\n",
    "    l = df.Low\n",
    "    c = df.Close # should this be \n",
    "    k = 0.34 / (1.34 + (lookback+1)/(lookback-1))\n",
    "    cc = np.log(c/c.shift(1))\n",
    "    ho = np.log(h/o)\n",
    "    lo = np.log(l/o)\n",
    "    co = np.log(c/o)\n",
    "    oc = np.log(o/c.shift(1))\n",
    "    oc_sq = oc**2\n",
    "    cc_sq = cc**2\n",
    "    rs = ho*(ho-co)+lo*(lo-co)\n",
    "    #close_vol = pd.rolling_sum(cc_sq, window=lookback) * (1.0 / (lookback - 1.0))\n",
    "    close_vol =  cc_sq.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    open_vol =  oc_sq.rolling(lookback).sum()  * (1.0 / (lookback - 1.0))\n",
    "    window_rs =  rs.rolling(lookback).sum()  * (1.0 / (lookback - 1.0))\n",
    "    result = (open_vol + k * close_vol + (1-k) * window_rs).apply(np.sqrt) \n",
    "    result[:lookback-1] = np.nan\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### IMPORt DATA AND CREATE MA of SIGNAL\n",
    "\n",
    "folder = \"../clean_equity_data/\"\n",
    "\n",
    "port_file = (\"../portfolios/eriks_port.xlsx\")\n",
    "\n",
    "\n",
    "current_port_tmp = pd.read_excel(port_file)\n",
    "current_cash = current_port_tmp.loc[current_port_tmp['Company'].isin([\"Cash\"])]\n",
    "current_port_tmp = current_port_tmp.loc[current_port_tmp['Current %']>0,]\n",
    "current_port_tmp = current_port_tmp.loc[~current_port_tmp['Company'].isin([\"Cash\", \"Total\"])]\n",
    "current_port = current_port_tmp[['Company','Current %' ]]\n",
    "current_port = current_port[~current_port['Company'].isna()]\n",
    "\n",
    "file_list = [\"GESTALT_2022-08-27.csv\",\"GESTALT_2022-08-27.csv\", \"GESTALT_2022-08-27.csv\" ]\n",
    "#file_list = [\"GESTALT_2022-06-29.csv\",\"GESTALT_2022-07-28.csv\", \"GESTALT_2022-08-27.csv\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Current %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arctic Paper</td>\n",
       "      <td>0.051785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dedicare</td>\n",
       "      <td>0.065439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rottneros</td>\n",
       "      <td>0.054350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>International Petroleum</td>\n",
       "      <td>0.043775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSAB B</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EnQuest</td>\n",
       "      <td>0.054869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B3 Consulting</td>\n",
       "      <td>0.037209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Wave</td>\n",
       "      <td>0.042049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Betsson</td>\n",
       "      <td>0.068411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prevas</td>\n",
       "      <td>0.051561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nilörngruppen</td>\n",
       "      <td>0.047719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BE Group</td>\n",
       "      <td>0.032342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TietoEVRY</td>\n",
       "      <td>0.075500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Clas Ohlson</td>\n",
       "      <td>0.053738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Softronic</td>\n",
       "      <td>0.047589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Africa Oil</td>\n",
       "      <td>0.054879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bilia</td>\n",
       "      <td>0.043748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company  Current %\n",
       "0              Arctic Paper   0.051785\n",
       "1                  Dedicare   0.065439\n",
       "2                 Rottneros   0.054350\n",
       "3   International Petroleum   0.043775\n",
       "4                    SSAB B   0.051500\n",
       "5                   EnQuest   0.054869\n",
       "6             B3 Consulting   0.037209\n",
       "7                  New Wave   0.042049\n",
       "8                   Betsson   0.068411\n",
       "9                    Prevas   0.051561\n",
       "11            Nilörngruppen   0.047719\n",
       "13                 BE Group   0.032342\n",
       "14                TietoEVRY   0.075500\n",
       "17              Clas Ohlson   0.053738\n",
       "18                Softronic   0.047589\n",
       "19               Africa Oil   0.054879\n",
       "20                    Bilia   0.043748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(file_list):\n",
    "    data_tmp = pd.read_csv(folder + file)\n",
    "    data_tmp.loc[:, 'Signal_' + str(idx)] =  np.linspace(1, -1, num=len(data_tmp))\n",
    "    data_tmp_clean = data_tmp[['Company','Yahoo', 'Signal_' + str(idx)]]\n",
    "    if idx == 0:\n",
    "        data_comb = data_tmp_clean\n",
    "    else:\n",
    "        data_comb = data_comb.merge(data_tmp_clean, how ='outer', on = ['Company','Yahoo'] )\n",
    "    \n",
    "    \n",
    "#Fill missing values with 0\n",
    "data_comb[data_comb.filter(like='Signal').columns] = data_comb[data_comb.filter(like='Signal').columns].fillna(value=0)\n",
    "\n",
    "### Get avergae signal value over the columns\n",
    "data_comb['Signal_avg'] = data_comb[data_comb.filter(like='Signal').columns].mean(axis = 1)\n",
    "sig_scaled = (2*data_comb['Signal_avg'])/ abs(data_comb['Signal_avg']).sum() #scale as aqr\n",
    "data_comb['Signal_avg'] = sig_scaled\n",
    "\n",
    "data_comb = data_comb.sort_values(by = 'Signal_avg', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pick top 50 stock\n",
    "\n",
    "top = data_comb[0:50][['Company','Yahoo', 'Signal_avg']] \n",
    "other_kept_stocks_idx = np.setdiff1d(current_port['Company'], top['Company'])\n",
    "other_kept_stocks = data_comb.loc[data_comb['Company'].isin(other_kept_stocks_idx), ['Company','Yahoo', 'Signal_avg']]\n",
    "\n",
    "#append, merge, get weights\n",
    "input_opti = top.append(other_kept_stocks[['Company','Yahoo', 'Signal_avg']])\n",
    "input_opti = input_opti.merge(current_port, on='Company', how = 'left')\n",
    "input_opti['Current %'] = input_opti['Current %'].fillna(0)\n",
    "\n",
    "\n",
    "input_opti = input_opti.merge(rank_data[['Company','Signal']], on = 'Company')\n",
    "input_opti.loc[:,'Short_sig'] = np.nan\n",
    "\n",
    "input_opti.loc[input_opti['Signal'] == 'Buy', 'Short_sig'] = 1\n",
    "input_opti.loc[input_opti['Signal'] == 'Neutral', 'Short_sig'] = 0\n",
    "input_opti.loc[input_opti['Signal'] == 'Sell', 'Short_sig'] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get Cov and YZ vol\n",
    "prices_df = pd.DataFrame()\n",
    "vol_yz = pd.DataFrame()\n",
    "for tick in input_opti['Yahoo']:\n",
    "    \n",
    "    price_imp_tmp = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "    price = price_imp_tmp['Adj Close']\n",
    "    price_tmp = pd.DataFrame(price)\n",
    "    price_tmp.columns = [tick]\n",
    "    prices_df = pd.concat([prices_df, price_tmp], axis = 1)\n",
    "    #append to array instead\n",
    "    vol_yz[tick] = get_hvol_yz(price_imp_tmp,lookback = 252).tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARP.ST</th>\n",
       "      <th>DEDI.ST</th>\n",
       "      <th>RROS.ST</th>\n",
       "      <th>IPCO.ST</th>\n",
       "      <th>SSAB-B.ST</th>\n",
       "      <th>ENQ.ST</th>\n",
       "      <th>B3.ST</th>\n",
       "      <th>NEWA-B.ST</th>\n",
       "      <th>BETS-B.ST</th>\n",
       "      <th>PREV-B.ST</th>\n",
       "      <th>...</th>\n",
       "      <th>ATCO-A.ST</th>\n",
       "      <th>SHOT.ST</th>\n",
       "      <th>POOL-B.ST</th>\n",
       "      <th>ABB.ST</th>\n",
       "      <th>STE-R.ST</th>\n",
       "      <th>HANZA.ST</th>\n",
       "      <th>PDX.ST</th>\n",
       "      <th>SKIS-B.ST</th>\n",
       "      <th>KIND-SDB.ST</th>\n",
       "      <th>FOI-B.ST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>0.037257</td>\n",
       "      <td>0.03048</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.038782</td>\n",
       "      <td>0.032534</td>\n",
       "      <td>0.027256</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023154</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.044225</td>\n",
       "      <td>0.032407</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.027295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ARP.ST  DEDI.ST   RROS.ST   IPCO.ST  SSAB-B.ST    ENQ.ST  \\\n",
       "Date                                                                     \n",
       "2022-09-16  0.037257  0.03048  0.028849  0.032601   0.027665  0.037346   \n",
       "\n",
       "               B3.ST  NEWA-B.ST  BETS-B.ST  PREV-B.ST  ...  ATCO-A.ST  \\\n",
       "Date                                                   ...              \n",
       "2022-09-16  0.038782   0.032534   0.027256   0.033649  ...   0.023154   \n",
       "\n",
       "             SHOT.ST  POOL-B.ST    ABB.ST  STE-R.ST  HANZA.ST    PDX.ST  \\\n",
       "Date                                                                      \n",
       "2022-09-16  0.029889        NaN  0.016087  0.022222  0.044225  0.032407   \n",
       "\n",
       "            SKIS-B.ST  KIND-SDB.ST  FOI-B.ST  \n",
       "Date                                          \n",
       "2022-09-16   0.023917     0.033863  0.027295  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_yz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyRMT\n",
    "%run pyrmt.ipynb #other functions \n",
    "\n",
    "vol_yz_ls = vol_yz.values\n",
    "vol_yz_ls[np.isnan(vol_yz_ls)] = np.nanmean(vol_yz_ls)\n",
    "\n",
    "\n",
    "log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "log_ret = log_ret.tail(300)\n",
    "log_ret = log_ret.fillna(log_ret.mean())\n",
    "\n",
    "\n",
    "#cov = pyRMT.optimalShrinkage(log_ret.tail(252) , return_covariance=True) #we want the regurlized\n",
    "corr = optimalShrinkage(log_ret.tail(252), method = 'IW') #regurlized\n",
    "cov = vol_yz_ls.T * corr * vol_yz_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cov, average_cor, shrink = shrinkage(np.array(log_ret.tail(252)))\n",
    "cov = pd.DataFrame(cov)\n",
    "\n",
    "cov.loc[len(cov)] = 0 # add cash\n",
    "cov.loc[:,len(cov.columns)] = 0 #add cash\n",
    "\n",
    "cov = np.matrix(cov)  ### annulize the volatility\n",
    "\n",
    "#shrink covariance further????\n",
    "#cov= 0.5* (np.diag(np.diag(cov)) + np.matrix(cov))\n",
    "cov= np.diag(np.diag(cov))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARS = np.diagonal(cov)\n",
    "stds = np.sqrt(VARS)\n",
    "###\n",
    "stds[np.isnan(stds)] = np.nanmean(stds)\n",
    "stds[stds>=(0.6/np.sqrt(252))] = (0.6)/np.sqrt(252) # more than 60 vol gets 60 vol at ret\n",
    "stds[stds<=(0.4/np.sqrt(252))] = (0.4)/np.sqrt(252) # less than 30 vol gets 30 vol at ret\n",
    "\n",
    "mu_tmp = np.append(input_opti['Signal_avg'], 0) #add cash\n",
    "mu = np.array(mu_tmp) * stds # should we assume same sharpe ratios for all assets? Yes but cap at 60 vol, \n",
    "\n",
    "\n",
    "W_old_cash = np.append(np.array(input_opti['Current %']), current_cash['Current %']) \n",
    "#signals_cash = np.append(np.array(input_opti['Short_sig']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_port(mu, cov, w_old,VARS, mins, maxs, C, max_pos = 100):\n",
    "    np.random.seed(1)\n",
    "\n",
    "    n = len(mu)\n",
    "\n",
    "    b = cp.Variable(n, boolean = True)\n",
    "    max_positions = max_pos\n",
    "\n",
    "    w = cp.Variable(n)\n",
    "    ret = mu.T @ w\n",
    "    risk = cp.quad_form(w, cov)\n",
    "\n",
    "\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(ret -  risk - cp.norm(cp.multiply(C,w-w_old))),\n",
    "                     [cp.sum(w) == 1, # all weights sum to one\n",
    "                      w >= 0, #no negative weights\n",
    "                     w>= cp.multiply(b, mins), # max position if we have one\n",
    "                     w<= cp.multiply(b, maxs),# min position if we have one\n",
    "                    cp.sum(b) <=max_positions, # maximum of active positions\n",
    "                     # mu == 2 * cov @ w # first order constraint\n",
    "                     ]) \n",
    "\n",
    "    prob.solve()\n",
    "    return(w.value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import cvxpy as cp\n",
    "\n",
    "N_sim = 1000\n",
    "port_weight = np.zeros((len(mu), N_sim))\n",
    "\n",
    "N_sub = round(len(mu)**0.8)\n",
    "C = (mu[0]-mu[4]) #* (np.sqrt(VARS) / np.median(np.sqrt(VARS))) #transaction costs, this is one way\n",
    "\n",
    "#C = (mu_tmp[0] - mu_tmp[9])# * np.sqrt(VARS)\n",
    "\n",
    "\n",
    "maxs = np.ones(len(mu)) * 0.75 #* 0.075 # can be array\n",
    "#make cash 1\n",
    "maxs[-1] = 1\n",
    "mins = np.ones(len(mu)) * 0.01 # can be array\n",
    "#make cash 0\n",
    "mins[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for III in range(N_sim):\n",
    "\n",
    "\n",
    "#     ran_samp_idx = random.sample(range(0, len(mu)), N_sub)\n",
    "\n",
    "#     mu_tmp = mu[ran_samp_idx]\n",
    "#     cov_tmp = np.matrix(pd.DataFrame(cov).iloc[ran_samp_idx, ran_samp_idx])\n",
    "#     w_old_tmp = W_old_cash[ran_samp_idx]\n",
    "#     VARS_tmp = VARS[ran_samp_idx]\n",
    "#     mins_tmp = mins[ran_samp_idx]\n",
    "#     maxs_tmp = maxs[ran_samp_idx]\n",
    "#     C_tmp = C[ran_samp_idx]\n",
    "    \n",
    "#     weights_tmp = optimize_port(mu_tmp,cov_tmp, w_old_tmp,VARS_tmp, mins =mins_tmp, maxs =maxs_tmp, C =C_tmp)\n",
    "\n",
    "    \n",
    "#     port_weight[ran_samp_idx,III] = weights_tmp\n",
    "\n",
    "# resamp_port = pd.DataFrame(port_weight).mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = optimize_port(mu,cov, W_old_cash,VARS, mins =mins, maxs =maxs, C =C,max_pos = 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT\n",
    "https://thequantmba.wordpress.com/2016/12/14/risk-parityrisk-budgeting-portfolio-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _assets_risk_contribution_to_allocation_risk(weights, covariances):\n",
    "    # We calculate the risk of the weights distribution\n",
    "    #portfolio_risk = _allocation_risk(weights, covariances)\n",
    "    # We calculate the contribution of each asset to the risk of the weights\n",
    "    # distribution\n",
    "    assets_risk_contribution = weights @ np.multiply(covariances, weights.T)\n",
    "    assets_risk_contribution_sum = assets_risk_contribution.sum()\n",
    "    assets_risk_contribution_adj = assets_risk_contribution/assets_risk_contribution_sum\n",
    "    \n",
    "    # It returns the contribution of each asset to the risk of the weights\n",
    "    # distribution\n",
    "    return assets_risk_contribution_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _risk_budget_objective_error(weights, args):\n",
    "    # The covariance matrix occupies the first position in the variable\n",
    "    covariances = args[0]\n",
    "   \n",
    "    assets_risk_budget = args[1]\n",
    "    \n",
    "    weights = np.matrix(weights)\n",
    "    \n",
    "    assets_risk_contribution = _assets_risk_contribution_to_allocation_risk(weights, covariances)\n",
    "    \n",
    "    error = sum(np.abs(np.array(assets_risk_contribution)[0] - assets_risk_budget))#[0, 0]\n",
    "    \n",
    "    # It returns the calculated error\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_risk_parity_weights(covariances, assets_risk_budget, initial_weights):\n",
    "    # Restrictions to consider in the optimisation: only long positions whose\n",
    "    # sum equals 100%\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0},\n",
    "                       {'type': 'ineq', 'fun': lambda x: x})\n",
    "    # Optimisation process in scipy\n",
    "    optimize_result = minimize(fun=_risk_budget_objective_error,\n",
    "    x0=initial_weights,\n",
    "    args=[covariances, assets_risk_budget],\n",
    "    method='SLSQP',\n",
    "    constraints=constraints,\n",
    "    tol=TOLERANCE,\n",
    "    options={'disp': False})\n",
    "    # Recover the weights from the optimised object\n",
    "    weights = optimize_result.x\n",
    "    # It returns the optimised weights\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.optimize import minimize\n",
    "TOLERANCE = 1e-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "### EXPERIMENT\n",
    "# SIGNAL WEIGHT\n",
    "# SIGNAL WEIGHT RISK ALLOCATION IN ERC \n",
    "# OVER ALL SAME RULES AS THE CURRENT ONES\n",
    "TOP_N = 20\n",
    "\n",
    "rank_df = data_comb.copy()\n",
    "\n",
    "rank_df['rank'] = rank_df['Signal_avg'].rank()\n",
    "mean_rank = rank_df['rank'].mean()\n",
    "rank_df['rank_adj'] = rank_df['rank'] - mean_rank\n",
    "rank_df['rank_w'] = rank_df['rank_adj']/mean_rank\n",
    "\n",
    "top_signal = rank_df.loc[:TOP_N-1,:]\n",
    "adj_sig_w = top_signal['rank_w']/top_signal['rank_w'].sum()\n",
    "top_signal.loc[:,'adj_sig_w'] = adj_sig_w\n",
    "cov_tmp = np.matrix(pd.DataFrame(cov).loc[:TOP_N-1, :TOP_N-1])\n",
    "\n",
    "\n",
    "initial_weights = np.ones(TOP_N)/TOP_N\n",
    "assets_risk_budget = np.linspace(1, 0.5, num=TOP_N) #adj_sig_w # or say that we want stock nr 50 to have half the risk of the 1st? \n",
    "assets_risk_budget = assets_risk_budget/assets_risk_budget.sum()\n",
    "covariances = cov_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.190817819903884e-13\n",
      "            Iterations: 43\n",
      "            Function evaluations: 1008\n",
      "            Gradient evaluations: 43\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import inv,pinv\n",
    "from scipy.optimize import minimize\n",
    "\n",
    " # risk budgeting optimization\n",
    "def calculate_portfolio_var(w,V):\n",
    "    # function that calculates portfolio risk\n",
    "    w = np.matrix(w)\n",
    "    return (w*V*w.T)[0,0]\n",
    "\n",
    "def calculate_risk_contribution(w,V):\n",
    "    # function that calculates asset contribution to total risk\n",
    "    w = np.matrix(w)\n",
    "    sigma = np.sqrt(calculate_portfolio_var(w,V))\n",
    "    # Marginal Risk Contribution\n",
    "    MRC = V*w.T\n",
    "    # Risk Contribution\n",
    "    RC = np.multiply(MRC,w.T)/sigma\n",
    "    return RC\n",
    "\n",
    "def risk_budget_objective(x,pars):\n",
    "    # calculate portfolio risk\n",
    "    V = pars[0]# covariance table\n",
    "    x_t = pars[1] # risk target in percent of portfolio risk\n",
    "    sig_p =  np.sqrt(calculate_portfolio_var(x,V)) # portfolio sigma\n",
    "    risk_target = np.asmatrix(np.multiply(sig_p,x_t))\n",
    "    asset_RC = calculate_risk_contribution(x,V)\n",
    "    J = sum(np.square(asset_RC-risk_target.T))[0,0] *10000000 # sum of squared error\n",
    "    return J\n",
    "\n",
    "def total_weight_constraint(x):\n",
    "    return np.sum(x)-1.0\n",
    "\n",
    "def long_only_constraint(x):\n",
    "    return x\n",
    "\n",
    "V = covariances\n",
    "\n",
    "vol_inv = 1/np.diag(V)\n",
    "vol_inv = vol_inv / vol_inv.sum()\n",
    "\n",
    "x_t = assets_risk_budget # your risk budget percent of total portfolio risk (equal risk)\n",
    "\n",
    "cons = ({'type': 'eq', 'fun': total_weight_constraint},\n",
    "{'type': 'ineq', 'fun': long_only_constraint})\n",
    "res= minimize(risk_budget_objective, x0=vol_inv,\n",
    "              args=[V,x_t], method='SLSQP',constraints=cons, #SLSQP\n",
    "              options={'disp': True, 'maxiter': 100000, 'ftol' : 1e-100}, tol = 1e-1000)\n",
    "w_rb = np.asmatrix(res.x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.04782859, 0.05768829, 0.06012225, 0.05245749, 0.0609287 ,\n",
       "         0.04446497, 0.04216555, 0.04947084, 0.05809033, 0.04626343,\n",
       "         0.03304225, 0.0441739 , 0.04768612, 0.0372904 , 0.05478368,\n",
       "         0.08357087, 0.04455812, 0.03481671, 0.05115455, 0.04944296]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.06666666, 0.06491228, 0.06315789, 0.0614035 , 0.05964912,\n",
       "         0.05789473, 0.05614034, 0.05438596, 0.05263158, 0.05087719,\n",
       "         0.0491228 , 0.04736842, 0.04561404, 0.04385964, 0.04210527,\n",
       "         0.0403509 , 0.03859649, 0.0368421 , 0.03508773, 0.03333334]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_assets_risk_contribution_to_allocation_risk(w_rb, covariances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06666667, 0.06491228, 0.06315789, 0.06140351, 0.05964912,\n",
       "       0.05789474, 0.05614035, 0.05438596, 0.05263158, 0.05087719,\n",
       "       0.04912281, 0.04736842, 0.04561404, 0.04385965, 0.04210526,\n",
       "       0.04035088, 0.03859649, 0.03684211, 0.03508772, 0.03333333])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets_risk_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "DCPError",
     "evalue": "Problem does not follow DCP rules. Specifically:\nThe objective is not DCP. Its following subexpressions are not:\nvar198 * [[ 1.38811149e-03  5.63018649e-05  4.76137045e-05 -5.34177040e-05\n  -4.19857631e-05 -6.44365253e-06 -4.84865110e-05  9.80951016e-07\n   5.82187082e-06 -4.30380477e-05 -1.59653076e-05 -3.78612111e-05\n   2.67508161e-05 -3.21821512e-05  2.70166432e-05  5.49201040e-05\n  -5.84928799e-05 -5.14384934e-05 -5.74777045e-05 -1.37848391e-05]\n [ 5.63018649e-05  9.29056813e-04 -3.90431653e-05  7.16643504e-05\n  -6.71343352e-05  6.42713743e-05 -3.14740051e-05 -5.20512003e-05\n  -1.54700124e-05 -2.95740793e-05 -5.94330920e-05  5.72340353e-06\n  -9.54468785e-05 -9.49507812e-05 -3.97448237e-06 -3.43027448e-05\n   8.51162007e-05  4.39962106e-06 -3.13886262e-05 -5.03981123e-05]\n [ 4.76137045e-05 -3.90431653e-05  8.32238928e-04  1.32717275e-05\n   4.32661708e-06 -5.10688538e-05  1.65624201e-06 -5.36077501e-05\n   4.21999939e-05 -3.29496621e-05 -8.20904168e-05 -5.08654436e-05\n   2.26884543e-05 -3.19802467e-05 -5.41976745e-05  2.80258157e-06\n  -2.17963356e-05  9.36029532e-05  5.29254987e-06  2.23892052e-05]\n [-5.34177040e-05  7.16643504e-05  1.32717275e-05  1.06284266e-03\n  -5.23560122e-05  2.29072030e-04  1.74294412e-05 -1.41250183e-05\n   4.45069931e-06  4.63089746e-05 -1.44523449e-04  4.60318144e-05\n  -4.08199124e-05  2.16189948e-05 -8.67604657e-05  4.53469670e-05\n  -9.84547002e-05 -8.87619008e-05  4.36966972e-05  2.80004620e-05]\n [-4.19857631e-05 -6.71343352e-05  4.32661708e-06 -5.23560122e-05\n   7.65333970e-04 -8.74716474e-06 -4.54897677e-05 -1.06542364e-04\n   2.50097906e-05 -3.84797482e-05 -1.76685121e-04  4.85324740e-05\n  -1.11818147e-04  8.34351736e-05 -8.58465266e-05 -6.17154032e-05\n   1.95271379e-05 -1.61457178e-04 -3.71826143e-05 -4.23035137e-05]\n [-6.44365253e-06  6.42713743e-05 -5.10688538e-05  2.29072030e-04\n  -8.74716474e-06  1.39474177e-03 -1.19759450e-04  1.12637218e-04\n   2.39615838e-05 -3.78779889e-05 -8.50051779e-05 -3.94156094e-05\n   9.79826138e-06 -6.21281823e-05 -1.05287989e-04 -4.02829229e-06\n  -2.09351243e-05 -7.92785166e-05 -3.07291440e-05 -3.67465589e-05]\n [-4.84865110e-05 -3.14740051e-05  1.65624201e-06  1.74294412e-05\n  -4.54897677e-05 -1.19759450e-04  1.50400833e-03 -9.85994236e-05\n   3.02035033e-06  1.26370654e-04  2.78097384e-05 -2.23335203e-05\n   1.46759594e-05 -1.35391832e-04 -2.40212055e-05  1.15547227e-05\n  -4.60619215e-05  1.79551368e-05  3.70689205e-05 -2.48559692e-05]\n [ 9.80951016e-07 -5.20512003e-05 -5.36077501e-05 -1.41250183e-05\n  -1.06542364e-04  1.12637218e-04 -9.85994236e-05  1.05847137e-03\n   4.87527476e-05 -5.06261387e-05  6.14458053e-06  2.21931077e-05\n   1.08886471e-04  4.63348647e-05 -4.23248837e-06  4.07916067e-06\n  -7.52580233e-05  8.47302361e-05 -1.04843691e-05  4.25179223e-05]\n [ 5.82187082e-06 -1.54700124e-05  4.21999939e-05  4.45069931e-06\n   2.50097906e-05  2.39615838e-05  3.02035033e-06  4.87527476e-05\n   7.42898470e-04  6.34089506e-06  3.51643787e-05 -1.31007058e-04\n   2.75487290e-05 -4.19897242e-05  5.82182126e-05 -7.26076039e-06\n  -7.62090648e-05  9.68312817e-06 -1.51832060e-06 -2.37053180e-05]\n [-4.30380477e-05 -2.95740793e-05 -3.29496621e-05  4.63089746e-05\n  -3.84797482e-05 -3.78779889e-05  1.26370654e-04 -5.06261387e-05\n   6.34089506e-06  1.13223942e-03  8.06114470e-06  6.30304048e-05\n   1.33410743e-04 -8.29390485e-05 -2.11379421e-05 -1.93516310e-05\n  -7.85301445e-05  4.76394959e-05 -6.92454536e-05 -3.44449322e-05]\n [-1.59653076e-05 -5.94330920e-05 -8.20904168e-05 -1.44523449e-04\n  -1.76685121e-04 -8.50051779e-05  2.78097384e-05  6.14458053e-06\n   3.51643787e-05  8.06114470e-06  2.14306146e-03 -6.66010796e-05\n   4.12647318e-05 -4.36436092e-05 -7.30723280e-05  7.65613832e-05\n  -4.55562452e-05 -3.24366157e-04  1.28403867e-04 -4.26220624e-05]\n [-3.78612111e-05  5.72340353e-06 -5.08654436e-05  4.60318144e-05\n   4.85324740e-05 -3.94156094e-05 -2.23335203e-05  2.21931077e-05\n  -1.31007058e-04  6.30304048e-05 -6.66010796e-05  1.15624056e-03\n  -1.19916091e-05 -1.35088725e-04  4.21223873e-05  1.78297584e-05\n   7.16866667e-06  4.85710353e-05 -5.00205945e-06 -7.97144443e-05]\n [ 2.67508161e-05 -9.54468785e-05  2.26884543e-05 -4.08199124e-05\n  -1.11818147e-04  9.79826138e-06  1.46759594e-05  1.08886471e-04\n   2.75487290e-05  1.33410743e-04  4.12647318e-05 -1.19916091e-05\n   9.55444171e-04 -1.95515561e-04 -1.09250404e-04 -1.76927009e-05\n   1.57250858e-05  9.75375343e-05 -2.32801945e-05  1.48523662e-05]\n [-3.21821512e-05 -9.49507812e-05 -3.19802467e-05  2.16189948e-05\n   8.34351736e-05 -6.21281823e-05 -1.35391832e-04  4.63348647e-05\n  -4.19897242e-05 -8.29390485e-05 -4.36436092e-05 -1.35088725e-04\n  -1.95515561e-04  1.50231816e-03  6.00751365e-05 -5.60916435e-05\n   8.29429592e-05  4.41137724e-05  6.02288990e-05 -1.58621234e-05]\n [ 2.70166432e-05 -3.97448237e-06 -5.41976745e-05 -8.67604657e-05\n  -8.58465266e-05 -1.05287989e-04 -2.40212055e-05 -4.23248837e-06\n   5.82182126e-05 -2.11379421e-05 -7.30723280e-05  4.21223873e-05\n  -1.09250404e-04  6.00751365e-05  6.68228362e-04  1.21192159e-05\n  -2.93081819e-05 -9.11976760e-05 -2.74861831e-05 -5.46580823e-05]\n [ 5.49201040e-05 -3.43027448e-05  2.80258157e-06  4.53469670e-05\n  -6.17154032e-05 -4.02829229e-06  1.15547227e-05  4.07916067e-06\n  -7.26076039e-06 -1.93516310e-05  7.65613832e-05  1.78297584e-05\n  -1.76927009e-05 -5.60916435e-05  1.21192159e-05  2.75190970e-04\n   3.21334457e-05 -7.15860765e-05 -4.15155814e-05 -2.21547113e-05]\n [-5.84928799e-05  8.51162007e-05 -2.17963356e-05 -9.84547002e-05\n   1.95271379e-05 -2.09351243e-05 -4.60619215e-05 -7.52580233e-05\n  -7.62090648e-05 -7.85301445e-05 -4.55562452e-05  7.16866667e-06\n   1.57250858e-05  8.29429592e-05 -2.93081819e-05  3.21334457e-05\n   9.25944361e-04 -1.04225620e-04  7.62577419e-08  1.68429202e-06]\n [-5.14384934e-05  4.39962106e-06  9.36029532e-05 -8.87619008e-05\n  -1.61457178e-04 -7.92785166e-05  1.79551368e-05  8.47302361e-05\n   9.68312817e-06  4.76394959e-05 -3.24366157e-04  4.85710353e-05\n   9.75375343e-05  4.41137724e-05 -9.11976760e-05 -7.15860765e-05\n  -1.04225620e-04  1.44763743e-03  9.29521551e-05  9.42063473e-05]\n [-5.74777045e-05 -3.13886262e-05  5.29254987e-06  4.36966972e-05\n  -3.71826143e-05 -3.07291440e-05  3.70689205e-05 -1.04843691e-05\n  -1.51832060e-06 -6.92454536e-05  1.28403867e-04 -5.00205945e-06\n  -2.32801945e-05  6.02288990e-05 -2.74861831e-05 -4.15155814e-05\n   7.62577419e-08  9.29521551e-05  6.38671602e-04  5.29300293e-06]\n [-1.37848391e-05 -5.03981123e-05  2.23892052e-05  2.80004620e-05\n  -4.23035137e-05 -3.67465589e-05 -2.48559692e-05  4.25179223e-05\n  -2.37053180e-05 -3.44449322e-05 -4.26220624e-05 -7.97144443e-05\n   1.48523662e-05 -1.58621234e-05 -5.46580823e-05 -2.21547113e-05\n   1.68429202e-06  9.42063473e-05  5.29300293e-06  6.49472398e-04]] * var198",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDCPError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-3684435719d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                      ]) \n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, solver, warm_start, verbose, parallel, gp, qcp, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     solver, warm_start, verbose, **kwargs)\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         data, solving_inverse_data = self._solving_chain.apply(\n\u001b[1;32m    570\u001b[0m             self._intermediate_problem)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_construct_chains\u001b[0;34m(self, solver, gp)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     def _solve(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_construct_chains\u001b[0;34m(self, solver, gp)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_chain\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                     \u001b[0mconstruct_intermediate_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_solvers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_problem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_inverse_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/cvxpy/reductions/solvers/intermediate_chain.py\u001b[0m in \u001b[0;36mconstruct_intermediate_chain\u001b[0;34m(problem, candidates, gp)\u001b[0m\n\u001b[1;32m     91\u001b[0m             append += (\"\\nHowever, the problem does follow DQCP rules. \"\n\u001b[1;32m     92\u001b[0m                        \"Consider calling solve() with `qcp=True`.\")\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDCPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Problem does not follow DCP rules. Specifically:\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dgp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDCPError\u001b[0m: Problem does not follow DCP rules. Specifically:\nThe objective is not DCP. Its following subexpressions are not:\nvar198 * [[ 1.38811149e-03  5.63018649e-05  4.76137045e-05 -5.34177040e-05\n  -4.19857631e-05 -6.44365253e-06 -4.84865110e-05  9.80951016e-07\n   5.82187082e-06 -4.30380477e-05 -1.59653076e-05 -3.78612111e-05\n   2.67508161e-05 -3.21821512e-05  2.70166432e-05  5.49201040e-05\n  -5.84928799e-05 -5.14384934e-05 -5.74777045e-05 -1.37848391e-05]\n [ 5.63018649e-05  9.29056813e-04 -3.90431653e-05  7.16643504e-05\n  -6.71343352e-05  6.42713743e-05 -3.14740051e-05 -5.20512003e-05\n  -1.54700124e-05 -2.95740793e-05 -5.94330920e-05  5.72340353e-06\n  -9.54468785e-05 -9.49507812e-05 -3.97448237e-06 -3.43027448e-05\n   8.51162007e-05  4.39962106e-06 -3.13886262e-05 -5.03981123e-05]\n [ 4.76137045e-05 -3.90431653e-05  8.32238928e-04  1.32717275e-05\n   4.32661708e-06 -5.10688538e-05  1.65624201e-06 -5.36077501e-05\n   4.21999939e-05 -3.29496621e-05 -8.20904168e-05 -5.08654436e-05\n   2.26884543e-05 -3.19802467e-05 -5.41976745e-05  2.80258157e-06\n  -2.17963356e-05  9.36029532e-05  5.29254987e-06  2.23892052e-05]\n [-5.34177040e-05  7.16643504e-05  1.32717275e-05  1.06284266e-03\n  -5.23560122e-05  2.29072030e-04  1.74294412e-05 -1.41250183e-05\n   4.45069931e-06  4.63089746e-05 -1.44523449e-04  4.60318144e-05\n  -4.08199124e-05  2.16189948e-05 -8.67604657e-05  4.53469670e-05\n  -9.84547002e-05 -8.87619008e-05  4.36966972e-05  2.80004620e-05]\n [-4.19857631e-05 -6.71343352e-05  4.32661708e-06 -5.23560122e-05\n   7.65333970e-04 -8.74716474e-06 -4.54897677e-05 -1.06542364e-04\n   2.50097906e-05 -3.84797482e-05 -1.76685121e-04  4.85324740e-05\n  -1.11818147e-04  8.34351736e-05 -8.58465266e-05 -6.17154032e-05\n   1.95271379e-05 -1.61457178e-04 -3.71826143e-05 -4.23035137e-05]\n [-6.44365253e-06  6.42713743e-05 -5.10688538e-05  2.29072030e-04\n  -8.74716474e-06  1.39474177e-03 -1.19759450e-04  1.12637218e-04\n   2.39615838e-05 -3.78779889e-05 -8.50051779e-05 -3.94156094e-05\n   9.79826138e-06 -6.21281823e-05 -1.05287989e-04 -4.02829229e-06\n  -2.09351243e-05 -7.92785166e-05 -3.07291440e-05 -3.67465589e-05]\n [-4.84865110e-05 -3.14740051e-05  1.65624201e-06  1.74294412e-05\n  -4.54897677e-05 -1.19759450e-04  1.50400833e-03 -9.85994236e-05\n   3.02035033e-06  1.26370654e-04  2.78097384e-05 -2.23335203e-05\n   1.46759594e-05 -1.35391832e-04 -2.40212055e-05  1.15547227e-05\n  -4.60619215e-05  1.79551368e-05  3.70689205e-05 -2.48559692e-05]\n [ 9.80951016e-07 -5.20512003e-05 -5.36077501e-05 -1.41250183e-05\n  -1.06542364e-04  1.12637218e-04 -9.85994236e-05  1.05847137e-03\n   4.87527476e-05 -5.06261387e-05  6.14458053e-06  2.21931077e-05\n   1.08886471e-04  4.63348647e-05 -4.23248837e-06  4.07916067e-06\n  -7.52580233e-05  8.47302361e-05 -1.04843691e-05  4.25179223e-05]\n [ 5.82187082e-06 -1.54700124e-05  4.21999939e-05  4.45069931e-06\n   2.50097906e-05  2.39615838e-05  3.02035033e-06  4.87527476e-05\n   7.42898470e-04  6.34089506e-06  3.51643787e-05 -1.31007058e-04\n   2.75487290e-05 -4.19897242e-05  5.82182126e-05 -7.26076039e-06\n  -7.62090648e-05  9.68312817e-06 -1.51832060e-06 -2.37053180e-05]\n [-4.30380477e-05 -2.95740793e-05 -3.29496621e-05  4.63089746e-05\n  -3.84797482e-05 -3.78779889e-05  1.26370654e-04 -5.06261387e-05\n   6.34089506e-06  1.13223942e-03  8.06114470e-06  6.30304048e-05\n   1.33410743e-04 -8.29390485e-05 -2.11379421e-05 -1.93516310e-05\n  -7.85301445e-05  4.76394959e-05 -6.92454536e-05 -3.44449322e-05]\n [-1.59653076e-05 -5.94330920e-05 -8.20904168e-05 -1.44523449e-04\n  -1.76685121e-04 -8.50051779e-05  2.78097384e-05  6.14458053e-06\n   3.51643787e-05  8.06114470e-06  2.14306146e-03 -6.66010796e-05\n   4.12647318e-05 -4.36436092e-05 -7.30723280e-05  7.65613832e-05\n  -4.55562452e-05 -3.24366157e-04  1.28403867e-04 -4.26220624e-05]\n [-3.78612111e-05  5.72340353e-06 -5.08654436e-05  4.60318144e-05\n   4.85324740e-05 -3.94156094e-05 -2.23335203e-05  2.21931077e-05\n  -1.31007058e-04  6.30304048e-05 -6.66010796e-05  1.15624056e-03\n  -1.19916091e-05 -1.35088725e-04  4.21223873e-05  1.78297584e-05\n   7.16866667e-06  4.85710353e-05 -5.00205945e-06 -7.97144443e-05]\n [ 2.67508161e-05 -9.54468785e-05  2.26884543e-05 -4.08199124e-05\n  -1.11818147e-04  9.79826138e-06  1.46759594e-05  1.08886471e-04\n   2.75487290e-05  1.33410743e-04  4.12647318e-05 -1.19916091e-05\n   9.55444171e-04 -1.95515561e-04 -1.09250404e-04 -1.76927009e-05\n   1.57250858e-05  9.75375343e-05 -2.32801945e-05  1.48523662e-05]\n [-3.21821512e-05 -9.49507812e-05 -3.19802467e-05  2.16189948e-05\n   8.34351736e-05 -6.21281823e-05 -1.35391832e-04  4.63348647e-05\n  -4.19897242e-05 -8.29390485e-05 -4.36436092e-05 -1.35088725e-04\n  -1.95515561e-04  1.50231816e-03  6.00751365e-05 -5.60916435e-05\n   8.29429592e-05  4.41137724e-05  6.02288990e-05 -1.58621234e-05]\n [ 2.70166432e-05 -3.97448237e-06 -5.41976745e-05 -8.67604657e-05\n  -8.58465266e-05 -1.05287989e-04 -2.40212055e-05 -4.23248837e-06\n   5.82182126e-05 -2.11379421e-05 -7.30723280e-05  4.21223873e-05\n  -1.09250404e-04  6.00751365e-05  6.68228362e-04  1.21192159e-05\n  -2.93081819e-05 -9.11976760e-05 -2.74861831e-05 -5.46580823e-05]\n [ 5.49201040e-05 -3.43027448e-05  2.80258157e-06  4.53469670e-05\n  -6.17154032e-05 -4.02829229e-06  1.15547227e-05  4.07916067e-06\n  -7.26076039e-06 -1.93516310e-05  7.65613832e-05  1.78297584e-05\n  -1.76927009e-05 -5.60916435e-05  1.21192159e-05  2.75190970e-04\n   3.21334457e-05 -7.15860765e-05 -4.15155814e-05 -2.21547113e-05]\n [-5.84928799e-05  8.51162007e-05 -2.17963356e-05 -9.84547002e-05\n   1.95271379e-05 -2.09351243e-05 -4.60619215e-05 -7.52580233e-05\n  -7.62090648e-05 -7.85301445e-05 -4.55562452e-05  7.16866667e-06\n   1.57250858e-05  8.29429592e-05 -2.93081819e-05  3.21334457e-05\n   9.25944361e-04 -1.04225620e-04  7.62577419e-08  1.68429202e-06]\n [-5.14384934e-05  4.39962106e-06  9.36029532e-05 -8.87619008e-05\n  -1.61457178e-04 -7.92785166e-05  1.79551368e-05  8.47302361e-05\n   9.68312817e-06  4.76394959e-05 -3.24366157e-04  4.85710353e-05\n   9.75375343e-05  4.41137724e-05 -9.11976760e-05 -7.15860765e-05\n  -1.04225620e-04  1.44763743e-03  9.29521551e-05  9.42063473e-05]\n [-5.74777045e-05 -3.13886262e-05  5.29254987e-06  4.36966972e-05\n  -3.71826143e-05 -3.07291440e-05  3.70689205e-05 -1.04843691e-05\n  -1.51832060e-06 -6.92454536e-05  1.28403867e-04 -5.00205945e-06\n  -2.32801945e-05  6.02288990e-05 -2.74861831e-05 -4.15155814e-05\n   7.62577419e-08  9.29521551e-05  6.38671602e-04  5.29300293e-06]\n [-1.37848391e-05 -5.03981123e-05  2.23892052e-05  2.80004620e-05\n  -4.23035137e-05 -3.67465589e-05 -2.48559692e-05  4.25179223e-05\n  -2.37053180e-05 -3.44449322e-05 -4.26220624e-05 -7.97144443e-05\n   1.48523662e-05 -1.58621234e-05 -5.46580823e-05 -2.21547113e-05\n   1.68429202e-06  9.42063473e-05  5.29300293e-06  6.49472398e-04]] * var198"
     ]
    }
   ],
   "source": [
    "#use cvxpy? \n",
    "\n",
    "np.random.seed(1)\n",
    "n = TOP_N\n",
    "b = cp.Variable(n, boolean = True)\n",
    "\n",
    "\n",
    "w = cp.Variable(n)\n",
    "risk_cont = w@(cov_tmp * w)\n",
    "risk = cp.sum(risk_cont)\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(risk ),\n",
    "                     [ #no negative weights\n",
    "                     ]) \n",
    "\n",
    "prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.38811149e-03,  5.63018649e-05,  4.76137045e-05,\n",
       "         -5.34177040e-05, -4.19857631e-05, -6.44365253e-06,\n",
       "         -4.84865110e-05,  9.80951016e-07,  5.82187082e-06,\n",
       "         -4.30380477e-05, -1.59653076e-05, -3.78612111e-05,\n",
       "          2.67508161e-05, -3.21821512e-05,  2.70166432e-05,\n",
       "          5.49201040e-05, -5.84928799e-05, -5.14384934e-05,\n",
       "         -5.74777045e-05, -1.37848391e-05],\n",
       "        [ 5.63018649e-05,  9.29056813e-04, -3.90431653e-05,\n",
       "          7.16643504e-05, -6.71343352e-05,  6.42713743e-05,\n",
       "         -3.14740051e-05, -5.20512003e-05, -1.54700124e-05,\n",
       "         -2.95740793e-05, -5.94330920e-05,  5.72340353e-06,\n",
       "         -9.54468785e-05, -9.49507812e-05, -3.97448237e-06,\n",
       "         -3.43027448e-05,  8.51162007e-05,  4.39962106e-06,\n",
       "         -3.13886262e-05, -5.03981123e-05],\n",
       "        [ 4.76137045e-05, -3.90431653e-05,  8.32238928e-04,\n",
       "          1.32717275e-05,  4.32661708e-06, -5.10688538e-05,\n",
       "          1.65624201e-06, -5.36077501e-05,  4.21999939e-05,\n",
       "         -3.29496621e-05, -8.20904168e-05, -5.08654436e-05,\n",
       "          2.26884543e-05, -3.19802467e-05, -5.41976745e-05,\n",
       "          2.80258157e-06, -2.17963356e-05,  9.36029532e-05,\n",
       "          5.29254987e-06,  2.23892052e-05],\n",
       "        [-5.34177040e-05,  7.16643504e-05,  1.32717275e-05,\n",
       "          1.06284266e-03, -5.23560122e-05,  2.29072030e-04,\n",
       "          1.74294412e-05, -1.41250183e-05,  4.45069931e-06,\n",
       "          4.63089746e-05, -1.44523449e-04,  4.60318144e-05,\n",
       "         -4.08199124e-05,  2.16189948e-05, -8.67604657e-05,\n",
       "          4.53469670e-05, -9.84547002e-05, -8.87619008e-05,\n",
       "          4.36966972e-05,  2.80004620e-05],\n",
       "        [-4.19857631e-05, -6.71343352e-05,  4.32661708e-06,\n",
       "         -5.23560122e-05,  7.65333970e-04, -8.74716474e-06,\n",
       "         -4.54897677e-05, -1.06542364e-04,  2.50097906e-05,\n",
       "         -3.84797482e-05, -1.76685121e-04,  4.85324740e-05,\n",
       "         -1.11818147e-04,  8.34351736e-05, -8.58465266e-05,\n",
       "         -6.17154032e-05,  1.95271379e-05, -1.61457178e-04,\n",
       "         -3.71826143e-05, -4.23035137e-05],\n",
       "        [-6.44365253e-06,  6.42713743e-05, -5.10688538e-05,\n",
       "          2.29072030e-04, -8.74716474e-06,  1.39474177e-03,\n",
       "         -1.19759450e-04,  1.12637218e-04,  2.39615838e-05,\n",
       "         -3.78779889e-05, -8.50051779e-05, -3.94156094e-05,\n",
       "          9.79826138e-06, -6.21281823e-05, -1.05287989e-04,\n",
       "         -4.02829229e-06, -2.09351243e-05, -7.92785166e-05,\n",
       "         -3.07291440e-05, -3.67465589e-05],\n",
       "        [-4.84865110e-05, -3.14740051e-05,  1.65624201e-06,\n",
       "          1.74294412e-05, -4.54897677e-05, -1.19759450e-04,\n",
       "          1.50400833e-03, -9.85994236e-05,  3.02035033e-06,\n",
       "          1.26370654e-04,  2.78097384e-05, -2.23335203e-05,\n",
       "          1.46759594e-05, -1.35391832e-04, -2.40212055e-05,\n",
       "          1.15547227e-05, -4.60619215e-05,  1.79551368e-05,\n",
       "          3.70689205e-05, -2.48559692e-05],\n",
       "        [ 9.80951016e-07, -5.20512003e-05, -5.36077501e-05,\n",
       "         -1.41250183e-05, -1.06542364e-04,  1.12637218e-04,\n",
       "         -9.85994236e-05,  1.05847137e-03,  4.87527476e-05,\n",
       "         -5.06261387e-05,  6.14458053e-06,  2.21931077e-05,\n",
       "          1.08886471e-04,  4.63348647e-05, -4.23248837e-06,\n",
       "          4.07916067e-06, -7.52580233e-05,  8.47302361e-05,\n",
       "         -1.04843691e-05,  4.25179223e-05],\n",
       "        [ 5.82187082e-06, -1.54700124e-05,  4.21999939e-05,\n",
       "          4.45069931e-06,  2.50097906e-05,  2.39615838e-05,\n",
       "          3.02035033e-06,  4.87527476e-05,  7.42898470e-04,\n",
       "          6.34089506e-06,  3.51643787e-05, -1.31007058e-04,\n",
       "          2.75487290e-05, -4.19897242e-05,  5.82182126e-05,\n",
       "         -7.26076039e-06, -7.62090648e-05,  9.68312817e-06,\n",
       "         -1.51832060e-06, -2.37053180e-05],\n",
       "        [-4.30380477e-05, -2.95740793e-05, -3.29496621e-05,\n",
       "          4.63089746e-05, -3.84797482e-05, -3.78779889e-05,\n",
       "          1.26370654e-04, -5.06261387e-05,  6.34089506e-06,\n",
       "          1.13223942e-03,  8.06114470e-06,  6.30304048e-05,\n",
       "          1.33410743e-04, -8.29390485e-05, -2.11379421e-05,\n",
       "         -1.93516310e-05, -7.85301445e-05,  4.76394959e-05,\n",
       "         -6.92454536e-05, -3.44449322e-05],\n",
       "        [-1.59653076e-05, -5.94330920e-05, -8.20904168e-05,\n",
       "         -1.44523449e-04, -1.76685121e-04, -8.50051779e-05,\n",
       "          2.78097384e-05,  6.14458053e-06,  3.51643787e-05,\n",
       "          8.06114470e-06,  2.14306146e-03, -6.66010796e-05,\n",
       "          4.12647318e-05, -4.36436092e-05, -7.30723280e-05,\n",
       "          7.65613832e-05, -4.55562452e-05, -3.24366157e-04,\n",
       "          1.28403867e-04, -4.26220624e-05],\n",
       "        [-3.78612111e-05,  5.72340353e-06, -5.08654436e-05,\n",
       "          4.60318144e-05,  4.85324740e-05, -3.94156094e-05,\n",
       "         -2.23335203e-05,  2.21931077e-05, -1.31007058e-04,\n",
       "          6.30304048e-05, -6.66010796e-05,  1.15624056e-03,\n",
       "         -1.19916091e-05, -1.35088725e-04,  4.21223873e-05,\n",
       "          1.78297584e-05,  7.16866667e-06,  4.85710353e-05,\n",
       "         -5.00205945e-06, -7.97144443e-05],\n",
       "        [ 2.67508161e-05, -9.54468785e-05,  2.26884543e-05,\n",
       "         -4.08199124e-05, -1.11818147e-04,  9.79826138e-06,\n",
       "          1.46759594e-05,  1.08886471e-04,  2.75487290e-05,\n",
       "          1.33410743e-04,  4.12647318e-05, -1.19916091e-05,\n",
       "          9.55444171e-04, -1.95515561e-04, -1.09250404e-04,\n",
       "         -1.76927009e-05,  1.57250858e-05,  9.75375343e-05,\n",
       "         -2.32801945e-05,  1.48523662e-05],\n",
       "        [-3.21821512e-05, -9.49507812e-05, -3.19802467e-05,\n",
       "          2.16189948e-05,  8.34351736e-05, -6.21281823e-05,\n",
       "         -1.35391832e-04,  4.63348647e-05, -4.19897242e-05,\n",
       "         -8.29390485e-05, -4.36436092e-05, -1.35088725e-04,\n",
       "         -1.95515561e-04,  1.50231816e-03,  6.00751365e-05,\n",
       "         -5.60916435e-05,  8.29429592e-05,  4.41137724e-05,\n",
       "          6.02288990e-05, -1.58621234e-05],\n",
       "        [ 2.70166432e-05, -3.97448237e-06, -5.41976745e-05,\n",
       "         -8.67604657e-05, -8.58465266e-05, -1.05287989e-04,\n",
       "         -2.40212055e-05, -4.23248837e-06,  5.82182126e-05,\n",
       "         -2.11379421e-05, -7.30723280e-05,  4.21223873e-05,\n",
       "         -1.09250404e-04,  6.00751365e-05,  6.68228362e-04,\n",
       "          1.21192159e-05, -2.93081819e-05, -9.11976760e-05,\n",
       "         -2.74861831e-05, -5.46580823e-05],\n",
       "        [ 5.49201040e-05, -3.43027448e-05,  2.80258157e-06,\n",
       "          4.53469670e-05, -6.17154032e-05, -4.02829229e-06,\n",
       "          1.15547227e-05,  4.07916067e-06, -7.26076039e-06,\n",
       "         -1.93516310e-05,  7.65613832e-05,  1.78297584e-05,\n",
       "         -1.76927009e-05, -5.60916435e-05,  1.21192159e-05,\n",
       "          2.75190970e-04,  3.21334457e-05, -7.15860765e-05,\n",
       "         -4.15155814e-05, -2.21547113e-05],\n",
       "        [-5.84928799e-05,  8.51162007e-05, -2.17963356e-05,\n",
       "         -9.84547002e-05,  1.95271379e-05, -2.09351243e-05,\n",
       "         -4.60619215e-05, -7.52580233e-05, -7.62090648e-05,\n",
       "         -7.85301445e-05, -4.55562452e-05,  7.16866667e-06,\n",
       "          1.57250858e-05,  8.29429592e-05, -2.93081819e-05,\n",
       "          3.21334457e-05,  9.25944361e-04, -1.04225620e-04,\n",
       "          7.62577419e-08,  1.68429202e-06],\n",
       "        [-5.14384934e-05,  4.39962106e-06,  9.36029532e-05,\n",
       "         -8.87619008e-05, -1.61457178e-04, -7.92785166e-05,\n",
       "          1.79551368e-05,  8.47302361e-05,  9.68312817e-06,\n",
       "          4.76394959e-05, -3.24366157e-04,  4.85710353e-05,\n",
       "          9.75375343e-05,  4.41137724e-05, -9.11976760e-05,\n",
       "         -7.15860765e-05, -1.04225620e-04,  1.44763743e-03,\n",
       "          9.29521551e-05,  9.42063473e-05],\n",
       "        [-5.74777045e-05, -3.13886262e-05,  5.29254987e-06,\n",
       "          4.36966972e-05, -3.71826143e-05, -3.07291440e-05,\n",
       "          3.70689205e-05, -1.04843691e-05, -1.51832060e-06,\n",
       "         -6.92454536e-05,  1.28403867e-04, -5.00205945e-06,\n",
       "         -2.32801945e-05,  6.02288990e-05, -2.74861831e-05,\n",
       "         -4.15155814e-05,  7.62577419e-08,  9.29521551e-05,\n",
       "          6.38671602e-04,  5.29300293e-06],\n",
       "        [-1.37848391e-05, -5.03981123e-05,  2.23892052e-05,\n",
       "          2.80004620e-05, -4.23035137e-05, -3.67465589e-05,\n",
       "         -2.48559692e-05,  4.25179223e-05, -2.37053180e-05,\n",
       "         -3.44449322e-05, -4.26220624e-05, -7.97144443e-05,\n",
       "          1.48523662e-05, -1.58621234e-05, -5.46580823e-05,\n",
       "         -2.21547113e-05,  1.68429202e-06,  9.42063473e-05,\n",
       "          5.29300293e-06,  6.49472398e-04]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_tmp * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_input_opti = input_opti.copy()\n",
    "\n",
    "new_input_opti.loc[len(new_input_opti.index)] = np.zeros(len(new_input_opti.columns))\n",
    "new_input_opti.loc[len(new_input_opti['Company'])-1,'Company'] = 'Cash'\n",
    "new_input_opti.loc[len(new_input_opti['Company'])-1,'Yahoo'] = 'Cash'\n",
    "new_input_opti.loc[len(new_input_opti['Company'])-1,'Current %'] = float(current_cash['Current %'])\n",
    "\n",
    "new_input_opti['new_weight'] = round_to_multiple(pd.DataFrame(weights), 0.001) \n",
    "\n",
    "#new_input_opti['new_weight'] = round_to_multiple(pd.DataFrame(resamp_port), 0.001)\n",
    "\n",
    "new_input_opti['vol'] = np.sqrt(np.diagonal(cov)) * np.sqrt(252)\n",
    "new_input_opti['mu'] = mu\n",
    "\n",
    "new_input_opti['sig/noise'] = new_input_opti['mu']/new_input_opti['vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_port = new_input_opti[(new_input_opti['Current %']>0) |  (new_input_opti['new_weight']>0)]\n",
    "new_port = new_port[['Company','Yahoo','Signal_avg','Current %','new_weight','Signal','sig/noise' ,'mu','vol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Yahoo</th>\n",
       "      <th>Signal_avg</th>\n",
       "      <th>Current %</th>\n",
       "      <th>new_weight</th>\n",
       "      <th>Signal</th>\n",
       "      <th>sig/noise</th>\n",
       "      <th>mu</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arctic Paper</td>\n",
       "      <td>ARP.ST</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.051785</td>\n",
       "      <td>0.075</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.559460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dedicare</td>\n",
       "      <td>DEDI.ST</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.065439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.416935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rottneros</td>\n",
       "      <td>RROS.ST</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>0.054350</td>\n",
       "      <td>0.062</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.449468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>International Petroleum</td>\n",
       "      <td>IPCO.ST</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.043775</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.473558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSAB B</td>\n",
       "      <td>SSAB-B.ST</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.053</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.422816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EnQuest</td>\n",
       "      <td>ENQ.ST</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.054869</td>\n",
       "      <td>0.069</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.616159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B3 Consulting</td>\n",
       "      <td>B3.ST</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.064</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.537407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Wave</td>\n",
       "      <td>NEWA-B.ST</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.042049</td>\n",
       "      <td>0.062</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.515721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Betsson</td>\n",
       "      <td>BETS-B.ST</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.068411</td>\n",
       "      <td>0.049</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.399387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prevas</td>\n",
       "      <td>PREV-B.ST</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>0.051561</td>\n",
       "      <td>0.062</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.514230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ShaMaran</td>\n",
       "      <td>SNM.ST</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.621538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nilörngruppen</td>\n",
       "      <td>NIL-B.ST</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.047719</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.501185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tethys Oil</td>\n",
       "      <td>TETY.ST</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.551774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BE Group</td>\n",
       "      <td>BEGR.ST</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.053</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.650617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TietoEVRY</td>\n",
       "      <td>TIETOS.ST</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.078</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.229769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bergs Timber</td>\n",
       "      <td>BRG-B.ST</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.447620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maha Energy</td>\n",
       "      <td>MAHA-A.ST</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.589137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Clas Ohlson</td>\n",
       "      <td>CLAS-B.ST</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.053738</td>\n",
       "      <td>0.033</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.386385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Softronic</td>\n",
       "      <td>SOF-B.ST</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>0.029</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.369564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Africa Oil</td>\n",
       "      <td>AOI.ST</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.054879</td>\n",
       "      <td>0.051</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.581027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bilia</td>\n",
       "      <td>BILI-A.ST</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.381266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FM Mattsson</td>\n",
       "      <td>FMM-B.ST</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.498070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Transtema</td>\n",
       "      <td>TRANS.ST</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.646285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Hanza Holding</td>\n",
       "      <td>HANZA.ST</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.673731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Cash</td>\n",
       "      <td>Cash</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123536</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company      Yahoo  Signal_avg  Current %  new_weight  \\\n",
       "0              Arctic Paper     ARP.ST    0.013245   0.051785       0.075   \n",
       "1                  Dedicare    DEDI.ST    0.013157   0.065439       0.000   \n",
       "2                 Rottneros    RROS.ST    0.013068   0.054350       0.062   \n",
       "3   International Petroleum    IPCO.ST    0.012980   0.043775       0.000   \n",
       "4                    SSAB B  SSAB-B.ST    0.012892   0.051500       0.053   \n",
       "5                   EnQuest     ENQ.ST    0.012804   0.054869       0.069   \n",
       "6             B3 Consulting      B3.ST    0.012715   0.037209       0.064   \n",
       "7                  New Wave  NEWA-B.ST    0.012627   0.042049       0.062   \n",
       "8                   Betsson  BETS-B.ST    0.012539   0.068411       0.049   \n",
       "9                    Prevas  PREV-B.ST    0.012450   0.051561       0.062   \n",
       "10                 ShaMaran     SNM.ST    0.012362   0.000000       0.055   \n",
       "11            Nilörngruppen   NIL-B.ST    0.012274   0.047719       0.000   \n",
       "12               Tethys Oil    TETY.ST    0.012185   0.000000       0.052   \n",
       "13                 BE Group    BEGR.ST    0.012097   0.032342       0.053   \n",
       "15                TietoEVRY  TIETOS.ST    0.011921   0.075500       0.078   \n",
       "16             Bergs Timber   BRG-B.ST    0.011832   0.000000       0.030   \n",
       "17              Maha Energy  MAHA-A.ST    0.011744   0.000000       0.050   \n",
       "18              Clas Ohlson  CLAS-B.ST    0.011656   0.053738       0.033   \n",
       "21                Softronic   SOF-B.ST    0.011391   0.047589       0.029   \n",
       "26               Africa Oil     AOI.ST    0.010949   0.054879       0.051   \n",
       "28                    Bilia  BILI-A.ST    0.010773   0.043748       0.000   \n",
       "30              FM Mattsson   FMM-B.ST    0.010596   0.000000       0.025   \n",
       "38                Transtema   TRANS.ST    0.009890   0.000000       0.027   \n",
       "45            Hanza Holding   HANZA.ST    0.009272   0.000000       0.020   \n",
       "50                     Cash       Cash    0.000000   0.123536       0.000   \n",
       "\n",
       "     Signal  sig/noise        mu       vol  \n",
       "0       Buy   0.000834  0.000467  0.559460  \n",
       "1   Neutral   0.000829  0.000346  0.416935  \n",
       "2       Buy   0.000823  0.000370  0.449468  \n",
       "3       Buy   0.000818  0.000387  0.473558  \n",
       "4   Neutral   0.000812  0.000343  0.422816  \n",
       "5       Buy   0.000785  0.000484  0.616159  \n",
       "6       Buy   0.000801  0.000430  0.537407  \n",
       "7   Neutral   0.000795  0.000410  0.515721  \n",
       "8       Buy   0.000791  0.000316  0.399387  \n",
       "9      Sell   0.000784  0.000403  0.514230  \n",
       "10  Neutral   0.000752  0.000467  0.621538  \n",
       "11      Buy   0.000773  0.000388  0.501185  \n",
       "12      Buy   0.000768  0.000424  0.551774  \n",
       "13  Neutral   0.000703  0.000457  0.650617  \n",
       "15      Buy   0.001307  0.000300  0.229769  \n",
       "16      Buy   0.000745  0.000334  0.447620  \n",
       "17      Buy   0.000740  0.000436  0.589137  \n",
       "18      Buy   0.000760  0.000294  0.386385  \n",
       "21     Sell   0.000777  0.000287  0.369564  \n",
       "26      Buy   0.000690  0.000401  0.581027  \n",
       "28     Sell   0.000712  0.000271  0.381266  \n",
       "30      Buy   0.000667  0.000332  0.498070  \n",
       "38      Buy   0.000578  0.000374  0.646285  \n",
       "45      Buy   0.000520  0.000350  0.673731  \n",
       "50      0.0        NaN  0.000000  0.000000  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### IDEA: Scale the target risks to signal average, scale back up? \n",
    "new_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.DataFrame()\n",
    "\n",
    "for tick in new_port['Yahoo']:\n",
    "    if tick == 'Cash':\n",
    "        prices_df[tick] = 10\n",
    "    else:\n",
    "        price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "        price = price['Adj Close']\n",
    "        prices_df[tick] = price\n",
    "    \n",
    "log_ret = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "log_ret = log_ret.dropna() \n",
    "\n",
    "hist_port = log_ret.mul(new_port['new_weight'].values, axis=1).sum(axis = 1).tail(252)\n",
    "\n",
    "prices_df = pd.DataFrame()\n",
    "for tick in [\"^OMX\"]:\n",
    "    \n",
    "    price = yf.download(tick,start='2000-01-01', progress = False, threads = False)\n",
    "    price = price['Adj Close']\n",
    "    prices_df[tick] = price\n",
    "log_ret_tmp = np.log(prices_df) - np.log(prices_df.shift(1))\n",
    "log_ret_tmp = log_ret_tmp.dropna()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = hist_port\n",
    "X = np.array(log_ret_tmp.tail(252))#.reshape(-1, 1)\n",
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_signal = pd.DataFrame([dparser.parse(latest_file,fuzzy=True).strftime(\"%d/%m/%Y\")])\n",
    "date_signal.columns = [\"Date\"]\n",
    "\n",
    "beta = pd.DataFrame([reg.coef_])\n",
    "beta.columns = [\"Beta\"]\n",
    "vol = pd.DataFrame([hist_port.tail(60).std() * np.sqrt(252)])\n",
    "vol.columns = [\"H-Vol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_write = pd.DataFrame([])\n",
    "\n",
    "Zeros =  [0] * max_positions\n",
    "Blanks = [\" \"] * max_positions\n",
    "\n",
    "clean_write.loc[:,'Antal'] = Zeros\n",
    "clean_write.loc[:,'Weight'] = Zeros\n",
    "clean_write.loc[:,'Company'] = Blanks\n",
    "clean_write.loc[:,'Ticker'] = Blanks\n",
    "clean_write.loc[:,'Signal'] = Blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "new_port = new_port.rename({ 'new_weight': 'Weight'}, axis=1)\n",
    "\n",
    "#add antal\n",
    "new_port = new_port.merge(current_port_tmp[['Company','Antal' ]], on = 'Company', how = 'outer')\n",
    "new_port.loc[new_port['Antal'].isna(),'Antal'] = 0\n",
    "new_port.loc[new_port['Weight'].isna(),'Weight'] = 0\n",
    "\n",
    "new_port = new_port.merge(signal_df[['Company','Ticker' ]], on = 'Company', how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove cash and insert seperatly\n",
    "\n",
    "new_cash = new_port.loc[new_port['Company'].isin([\"Cash\"])]\n",
    "new_port = new_port.loc[~new_port['Company'].isin([\"Cash\", \"Total\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write to excel file\n",
    "#current_port_tmp\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "book = load_workbook(port_file)\n",
    "writer = pd.ExcelWriter(port_file, engine='openpyxl') \n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "clean_write\n",
    "## CLEAN OLD FILE\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Company'], index = False, startcol = 1)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Ticker'], index = False, startcol = 2)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Antal'], index = False, startcol = 3)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Weight'], index = False, startcol = 4)\n",
    "clean_write.to_excel(writer, \"Gestalt\",columns=['Signal'], index = False, startcol = 10)\n",
    "\n",
    "\n",
    "## WRITE NEW PORTFOLIO TO FILE\n",
    "new_port.to_excel(writer, \"Gestalt\",columns=['Company'], index = False, startcol = 1)\n",
    "new_port.to_excel(writer, \"Gestalt\",columns=['Ticker'], index = False, startcol = 2)\n",
    "new_port.to_excel(writer, \"Gestalt\",columns=['Antal'], index = False, startcol = 3)\n",
    "new_port.to_excel(writer, \"Gestalt\",columns=['Weight'], index = False, startcol = 4)\n",
    "new_port.to_excel(writer, \"Gestalt\",columns=['Signal'], index = False, startcol = 10)\n",
    "\n",
    "\n",
    "date_signal.to_excel(writer, \"Gestalt\", index = False, startcol = 9, startrow=max_positions +1)\n",
    "beta.to_excel(writer, \"Gestalt\", index = False, startcol = 10, startrow=max_positions +1)\n",
    "vol.to_excel(writer, \"Gestalt\", index = False, startcol = 11, startrow=max_positions +1)\n",
    "\n",
    "\n",
    "\n",
    "new_cash.to_excel(writer, \"Gestalt\",columns=['Weight'], index = False, header = False, startcol = 4, startrow=max_positions +1)\n",
    "\n",
    "\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
